{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "numericos = ['AVProductsInstalled',\n",
    "'AVProductsEnabled',\n",
    "'Census_ProcessorCoreCount',\n",
    "'Census_PrimaryDiskTotalCapacity',\n",
    "'Census_SystemVolumeTotalCapacity',\n",
    "'Census_TotalPhysicalRAM',\n",
    "'Census_InternalPrimaryDiagonalDisplaySizeInInches',\n",
    "'Census_InternalPrimaryDisplayResolutionHorizontal',\n",
    "'Census_InternalPrimaryDisplayResolutionVertical',\n",
    "'Census_InternalBatteryNumberOfCharges']\n",
    "dtype = {}\n",
    "for df in pd.read_csv('encoding/final_sembat.csv',low_memory=False,chunksize=10):\n",
    "    for var in df.columns:\n",
    "        if var not in numericos:\n",
    "            dtype[var] = 'int8'\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterSampler\n",
    "import copy\n",
    "import gc\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "def hyper_parameter_optimization(params, modeloG, testX, testY, trainX, trainY):\n",
    "    lista_parametros = list(ParameterSampler(params, n_iter=10, random_state=10))\n",
    "    for elem in lista_parametros:\n",
    "        altera = False\n",
    "        for key, value in elem.items():\n",
    "            if key == 'solver':\n",
    "                if value in ['newton-cg','lbfgs','sag']:\n",
    "                    altera = True\n",
    "        if altera == True:\n",
    "            elem['penalty'] = 'l2'\n",
    "    tabelaFinal = []\n",
    "    for param in lista_parametros:\n",
    "        print(param)\n",
    "        modelo = copy.copy(modeloG)\n",
    "        modelo.set_params(**param)\n",
    "        #print(modelo.get_params())\n",
    "        modelo.fit(trainX,trainY)\n",
    "        pred = modelo.predict(testX)\n",
    "        false_positive_rate, true_positive_rate, thresholds = roc_curve(testY, pred)\n",
    "        score = auc(false_positive_rate, true_positive_rate)\n",
    "        elem = param.copy()\n",
    "        elem['score'] = score\n",
    "        tabelaFinal.append(elem)\n",
    "        del modelo\n",
    "        gc.collect()\n",
    "    return tabelaFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "auxPred = pd.DataFrame()\n",
    "i = 0\n",
    "for tp in pd.read_csv('encoding/final_sembat.csv',low_memory=False,chunksize=50000,dtype=dtype):\n",
    "#     if i == 55:\n",
    "#         break\n",
    "    if i == 0:\n",
    "        auxPred = pd.concat([auxPred,tp])\n",
    "    else:\n",
    "        auxPred = pd.concat([auxPred,tp],ignore_index=True)\n",
    "    i+=1\n",
    "    print(i)\n",
    "#aux = pd.read_csv('encoding/predict.csv',low_memory=False,dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 707)\n",
      "(50000, 707)\n",
      "(500000,)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "trainX = auxPred.loc[:499999, auxPred.columns != 'HasDetections']\n",
    "valX = auxPred.loc[500000:549999, auxPred.columns != 'HasDetections']\n",
    "trainY = auxPred.loc[:499999,'HasDetections']\n",
    "valY = auxPred.loc[500000:549999,'HasDetections']\n",
    "print(trainX.shape)\n",
    "print(valX.shape)\n",
    "print(trainY.shape)\n",
    "print(valY.shape)\n",
    "# parametros = {'C':[0.001,0.01,0.1,1],'penalty':['l1','l2'],'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "# m = LogisticRegression(max_iter=10000)\n",
    "# tabela = hyper_parameter_optimization(parametros,m,valX,valY,trainX,trainY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import math\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "def realizaVarThreshold():\n",
    "    indices = []\n",
    "    col = trainX.columns\n",
    "    total = len(col)\n",
    "    chunk = math.floor(total / 10)\n",
    "    print(chunk)\n",
    "    quantos = 0\n",
    "    for i in range(chunk):\n",
    "        sel = VarianceThreshold(threshold=0.001)\n",
    "        try:\n",
    "            sel.fit(trainX[col[quantos:quantos+10]])\n",
    "            aux = [i+quantos for i in sel.get_support(indices=True)]\n",
    "            indices.extend(aux)\n",
    "        except:\n",
    "            pass\n",
    "        del sel\n",
    "        gc.collect()\n",
    "        quantos = quantos+10\n",
    "    sel = VarianceThreshold(threshold=0.001)\n",
    "    try:\n",
    "        sel.fit(trainX[col[quantos:quantos+7]])\n",
    "        indices.extend(sel.get_support(indices=True))\n",
    "    except:\n",
    "        pass\n",
    "    del sel\n",
    "    gc.collect()\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "indices = realizaVarThreshold()\n",
    "print(len(indices))\n",
    "col = []\n",
    "coln = trainX.columns\n",
    "for i in indices:\n",
    "    col.append(coln[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del trainX\n",
    "del valX\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9c9a2cba73bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = auxPred.loc[:499999, col]\n",
    "valX = auxPred.loc[500000:549999, col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 16, 'max_features': 'auto', 'max_depth': 32, 'criterion': 'entropy'}\n",
      "{'n_estimators': 16, 'max_features': 'log2', 'max_depth': 32, 'criterion': 'entropy'}\n",
      "{'n_estimators': 16, 'max_features': 'log2', 'max_depth': 128, 'criterion': 'gini'}\n",
      "{'n_estimators': 32, 'max_features': 'auto', 'max_depth': None, 'criterion': 'gini'}\n",
      "{'n_estimators': 8, 'max_features': 'log2', 'max_depth': None, 'criterion': 'gini'}\n",
      "{'n_estimators': 8, 'max_features': 'log2', 'max_depth': 128, 'criterion': 'entropy'}\n",
      "{'n_estimators': 16, 'max_features': 'auto', 'max_depth': 128, 'criterion': 'gini'}\n",
      "{'n_estimators': 64, 'max_features': 'auto', 'max_depth': 32, 'criterion': 'gini'}\n",
      "{'n_estimators': 32, 'max_features': 'log2', 'max_depth': None, 'criterion': 'gini'}\n",
      "{'n_estimators': 100, 'max_features': 'log2', 'max_depth': 64, 'criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "n_estimators = [8, 16, 32, 64, 100]\n",
    "max_features = ['auto','log2']\n",
    "max_depth = [32,64,128,None]\n",
    "criterion = ['gini','entropy']\n",
    "parametros = {'n_estimators':n_estimators,'max_features':max_features,'max_depth':max_depth,'criterion':criterion}\n",
    "m = RandomForestClassifier()\n",
    "tabela = hyper_parameter_optimization(parametros,m,valX,valY,trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gini</td>\n",
       "      <td>32.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>64</td>\n",
       "      <td>0.667463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gini</td>\n",
       "      <td>64.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.658444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entropy</td>\n",
       "      <td>32.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>16</td>\n",
       "      <td>0.657307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>auto</td>\n",
       "      <td>32</td>\n",
       "      <td>0.655033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entropy</td>\n",
       "      <td>32.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.652853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>log2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.649633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gini</td>\n",
       "      <td>128.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>16</td>\n",
       "      <td>0.643742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gini</td>\n",
       "      <td>128.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.640022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>entropy</td>\n",
       "      <td>128.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.629723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>log2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.626342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion  max_depth max_features  n_estimators     score\n",
       "7      gini       32.0         auto            64  0.667463\n",
       "9      gini       64.0         log2           100  0.658444\n",
       "0   entropy       32.0         auto            16  0.657307\n",
       "3      gini        NaN         auto            32  0.655033\n",
       "1   entropy       32.0         log2            16  0.652853\n",
       "8      gini        NaN         log2            32  0.649633\n",
       "6      gini      128.0         auto            16  0.643742\n",
       "2      gini      128.0         log2            16  0.640022\n",
       "5   entropy      128.0         log2             8  0.629723\n",
       "4      gini        NaN         log2             8  0.626342"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tab = pd.DataFrame(tabela)\n",
    "tab.sort_values(by='score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auxPred.memory_usage().sum() / (1000*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxPred.loc[0:35000, auxPred.columns != 'HasDetections'].memory_usage().sum() / (1000*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(gamma='auto')\n",
    "clf.fit(auxPred.loc[0:35000, auxPred.columns != 'HasDetections'],auxPred.loc[0:35000,'HasDetections']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "n_estimators = [1, 2, 4, 8, 16, 32, 64]#, 100, 200]\n",
    "parametros = {'n_estimators':n_estimators}\n",
    "m = RandomForestClassifier()\n",
    "tabela = hyper_parameter_optimization(parametros,m,valX,valY,trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tab = pd.DataFrame(tabela)\n",
    "tab.sort_values(by='score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "min_samples_splits = np.linspace(0.1, 0.3, 5, endpoint=True)\n",
    "min_samples_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_leafs = np.linspace(0, 0.2, 5, endpoint=True)\n",
    "min_samples_leafs[0] = 0.00001\n",
    "list(min_samples_leafs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
