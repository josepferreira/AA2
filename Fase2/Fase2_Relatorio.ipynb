{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimização de hyper-parâmetros\n",
    "\n",
    "A ideia é que esta função selecione um número X de diferentes redes.\n",
    "\n",
    "Depois vamos criar uma função que para cada rede, vai fazer o treino e testar o score com os dados de validação. Essa função depois ordena consoante o melhor valor de AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterSampler\n",
    "import random as r\n",
    "def selecaoHyperParametros(d,neuronios):\n",
    "    lista_parametros = list(ParameterSampler(d, n_iter=10, random_state=10))\n",
    "    r.seed(10)\n",
    "    for var in lista_parametros:\n",
    "        var['topologia'] = r.choices(neuronios,k=var['nrCamadas'])\n",
    "    return lista_parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aqui estão os parametros que vamos optimizar\n",
    "\n",
    "### Faltam ainda ver o dropout, early stopping e regularização\n",
    "\n",
    "### Optimizer temos de ver os parâmetros existentes também:\n",
    "- rmsprop\n",
    "    - rho: float >= 0.\n",
    "    - epsilon: float >= 0. Fuzz factor. If None, defaults to K.epsilon().\n",
    "    - decay: float >= 0. Learning rate decay over each update.\n",
    "- SGD\n",
    "    - momentum: float >= 0. Parameter that accelerates SGD in the relevant direction and dampens oscillations.\n",
    "    - decay: float >= 0. Learning rate decay over each update.\n",
    "    - nesterov: boolean. Whether to apply Nesterov momentum.\n",
    "- Adam\n",
    "    - beta_1: float, 0 < beta < 1. Generally close to 1.\n",
    "    - beta_2: float, 0 < beta < 1. Generally close to 1.\n",
    "    - epsilon: float >= 0. Fuzz factor. If None, defaults to K.epsilon().\n",
    "    - decay: float >= 0. Learning rate decay over each update.\n",
    "    - amsgrad: boolean. Whether to apply the AMSGrad variant of this algorithm from the paper \"On the Convergence of Adam and Beyond\"\n",
    "    \n",
    "##### Todos têm learning rate!\n",
    "##### Existem ainda mais optimizers mas não sei se vale a pena ver todos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicionario = {\n",
    "    'nrCamadas':[1,2,3,4,5,6,7,8],\n",
    "    'ativacao':['relu','elu','exponential','tanh','sigmoid','linear'],\n",
    "    'epochs':[4,8,10,20],\n",
    "    'batch_size':[64,128,256,512]\n",
    "}\n",
    "neuronios = [2,3,4,5,8,10,16,32,64,128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'nrCamadas': 1, 'epochs': 20, 'batch_size': 128, 'ativacao': 'sigmoid', 'topologia': [10]}\n",
      "\n",
      "{'nrCamadas': 5, 'epochs': 8, 'batch_size': 512, 'ativacao': 'sigmoid', 'topologia': [8, 10, 4, 64, 64]}\n",
      "\n",
      "{'nrCamadas': 1, 'epochs': 8, 'batch_size': 256, 'ativacao': 'tanh', 'topologia': [16]}\n",
      "\n",
      "{'nrCamadas': 6, 'epochs': 4, 'batch_size': 256, 'ativacao': 'elu', 'topologia': [3, 10, 5, 4, 128, 128]}\n",
      "\n",
      "{'nrCamadas': 3, 'epochs': 8, 'batch_size': 256, 'ativacao': 'linear', 'topologia': [2, 64, 16]}\n",
      "\n",
      "{'nrCamadas': 4, 'epochs': 20, 'batch_size': 64, 'ativacao': 'relu', 'topologia': [5, 4, 16, 8]}\n",
      "\n",
      "{'nrCamadas': 6, 'epochs': 10, 'batch_size': 64, 'ativacao': 'exponential', 'topologia': [16, 16, 3, 32, 128, 128]}\n",
      "\n",
      "{'nrCamadas': 1, 'epochs': 4, 'batch_size': 256, 'ativacao': 'relu', 'topologia': [16]}\n",
      "\n",
      "{'nrCamadas': 1, 'epochs': 10, 'batch_size': 256, 'ativacao': 'linear', 'topologia': [2]}\n",
      "\n",
      "{'nrCamadas': 4, 'epochs': 20, 'batch_size': 256, 'ativacao': 'tanh', 'topologia': [2, 3, 128, 5]}\n"
     ]
    }
   ],
   "source": [
    "parametros = selecaoHyperParametros(dicionario,neuronios)\n",
    "for var in parametros:\n",
    "    print()\n",
    "    print(var)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
