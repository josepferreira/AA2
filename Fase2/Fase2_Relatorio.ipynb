{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimização de hyper-parâmetros\n",
    "\n",
    "A ideia é que esta função selecione um número X de diferentes redes.\n",
    "\n",
    "Depois vamos criar uma função que para cada rede, vai fazer o treino e testar o score com os dados de validação. Essa função depois ordena consoante o melhor valor de AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterSampler\n",
    "import random as r\n",
    "def selecaoHyperParametros(d,neuronios):\n",
    "    lista_parametros = list(ParameterSampler(d, n_iter=4, random_state=10))\n",
    "    r.seed(10)\n",
    "    for var in lista_parametros:\n",
    "        var['topologia'] = r.choices(neuronios,k=var['nrCamadas'])\n",
    "    return lista_parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import models,layers\n",
    "def criaRede(param,inputSize):\n",
    "    model=models.Sequential()\n",
    "    model.add(layers.Dense(param['topologia'][0],activation=param['ativacao'],input_shape=(inputSize,)))\n",
    "    for var in param['topologia'][1:]:\n",
    "        model.add(layers.Dense(var,activation=param['ativacao']))\n",
    "    model.add(layers.Dense(1,activation='sigmoid'))\n",
    "    model.compile(optimizer=param['optimizer'],\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "def optimizacaoHyperParametros(d,neuronios,trainX,trainY,valX,valY):\n",
    "    params = selecaoHyperParametros(d,neuronios)\n",
    "    for param in params:\n",
    "        print(param)\n",
    "        rede = criaRede(param,trainX.shape[1])\n",
    "        history = rede.fit(trainX,\n",
    "                                trainY,\n",
    "                                epochs=param['epochs'],\n",
    "                                batch_size=param['batch_size'],\n",
    "                                validation_data=(valX,valY))\n",
    "        pred = rede.predict(valX)\n",
    "        false_positive_rate, true_positive_rate, thresholds = roc_curve(valY, pred)\n",
    "        score = auc(false_positive_rate, true_positive_rate)\n",
    "        param['score'] = score\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aqui estão os parametros que vamos optimizar\n",
    "\n",
    "### Faltam ainda ver o dropout, early stopping e regularização\n",
    "\n",
    "### Optimizer temos de ver os parâmetros existentes também:\n",
    "- rmsprop\n",
    "    - rho: float >= 0.\n",
    "    - epsilon: float >= 0. Fuzz factor. If None, defaults to K.epsilon().\n",
    "    - decay: float >= 0. Learning rate decay over each update.\n",
    "- SGD\n",
    "    - momentum: float >= 0. Parameter that accelerates SGD in the relevant direction and dampens oscillations.\n",
    "    - decay: float >= 0. Learning rate decay over each update.\n",
    "    - nesterov: boolean. Whether to apply Nesterov momentum.\n",
    "- Adam\n",
    "    - beta_1: float, 0 < beta < 1. Generally close to 1.\n",
    "    - beta_2: float, 0 < beta < 1. Generally close to 1.\n",
    "    - epsilon: float >= 0. Fuzz factor. If None, defaults to K.epsilon().\n",
    "    - decay: float >= 0. Learning rate decay over each update.\n",
    "    - amsgrad: boolean. Whether to apply the AMSGrad variant of this algorithm from the paper \"On the Convergence of Adam and Beyond\"\n",
    "    \n",
    "##### Todos têm learning rate!\n",
    "##### Existem ainda mais optimizers mas não sei se vale a pena ver todos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicionario = {\n",
    "    'nrCamadas':[1,2,3,4,5,6,7,8],\n",
    "    'ativacao':['relu','elu','exponential','tanh','sigmoid','linear'],\n",
    "    'epochs':[4,8,10,20],\n",
    "    'batch_size':[64,128,256,512],\n",
    "    'optimizer':['rmsprop','adam','sgd']\n",
    "}\n",
    "neuronios = [2,3,4,5,8,10,16,32,64,128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feito\n",
      "Feito\n",
      "Feito\n",
      "Feito\n",
      "Feito\n",
      "Feito\n",
      "Feito\n",
      "Feito\n",
      "Feito\n",
      "Feito\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ms = None\n",
    "y = None\n",
    "for df in pd.read_csv('final_sembat.csv',low_memory=False,chunksize=60000):\n",
    "    if ms is None:\n",
    "        ms = df.iloc[:,0:10]\n",
    "        y = df['HasDetections']\n",
    "    else:\n",
    "        y = pd.concat([y, df['HasDetections']], ignore_index=True)\n",
    "        ms = pd.concat([ms,df.iloc[:,0:10]], ignore_index=True)\n",
    "    print('Feito')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = ms[:500000]\n",
    "valX = ms[500000:550000]\n",
    "trainY = y[:500000]\n",
    "valY = y[500000:550000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'optimizer': 'sgd', 'nrCamadas': 6, 'epochs': 8, 'batch_size': 128, 'ativacao': 'tanh', 'topologia': [10, 8, 10, 4, 64, 64]}\n",
      "Train on 500000 samples, validate on 50000 samples\n",
      "Epoch 1/8\n",
      "500000/500000 [==============================] - 5s 10us/step - loss: 0.6932 - acc: 0.5023 - val_loss: 0.6931 - val_acc: 0.5086\n",
      "Epoch 2/8\n",
      "500000/500000 [==============================] - 4s 9us/step - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6931 - val_acc: 0.5047\n",
      "Epoch 3/8\n",
      "500000/500000 [==============================] - 4s 9us/step - loss: 0.6930 - acc: 0.5064 - val_loss: 0.6930 - val_acc: 0.5086\n",
      "Epoch 4/8\n",
      "500000/500000 [==============================] - 4s 9us/step - loss: 0.6930 - acc: 0.5081 - val_loss: 0.6930 - val_acc: 0.5086\n",
      "Epoch 5/8\n",
      "500000/500000 [==============================] - 4s 9us/step - loss: 0.6930 - acc: 0.5088 - val_loss: 0.6930 - val_acc: 0.5109\n",
      "Epoch 6/8\n",
      "500000/500000 [==============================] - 5s 9us/step - loss: 0.6929 - acc: 0.5091 - val_loss: 0.6930 - val_acc: 0.5069\n",
      "Epoch 7/8\n",
      "500000/500000 [==============================] - 4s 9us/step - loss: 0.6929 - acc: 0.5099 - val_loss: 0.6929 - val_acc: 0.5087\n",
      "Epoch 8/8\n",
      "500000/500000 [==============================] - 5s 9us/step - loss: 0.6929 - acc: 0.5103 - val_loss: 0.6929 - val_acc: 0.5109\n",
      "{'optimizer': 'sgd', 'nrCamadas': 8, 'epochs': 8, 'batch_size': 128, 'ativacao': 'elu', 'topologia': [16, 3, 10, 5, 4, 128, 128, 2]}\n",
      "Train on 500000 samples, validate on 50000 samples\n",
      "Epoch 1/8\n",
      "500000/500000 [==============================] - 7s 14us/step - loss: 0.6930 - acc: 0.5062 - val_loss: 0.6929 - val_acc: 0.5125\n",
      "Epoch 2/8\n",
      "500000/500000 [==============================] - 7s 15us/step - loss: 0.6930 - acc: 0.5090 - val_loss: 0.6928 - val_acc: 0.5139\n",
      "Epoch 3/8\n",
      "500000/500000 [==============================] - 7s 14us/step - loss: 0.6930 - acc: 0.5107 - val_loss: 0.6928 - val_acc: 0.5139\n",
      "Epoch 4/8\n",
      "500000/500000 [==============================] - 7s 14us/step - loss: 0.6929 - acc: 0.5117 - val_loss: 0.6928 - val_acc: 0.5139\n",
      "Epoch 5/8\n",
      "500000/500000 [==============================] - 7s 14us/step - loss: 0.6929 - acc: 0.5115 - val_loss: 0.6927 - val_acc: 0.5139\n",
      "Epoch 6/8\n",
      "500000/500000 [==============================] - 7s 14us/step - loss: 0.6929 - acc: 0.5117 - val_loss: 0.6928 - val_acc: 0.5125\n",
      "Epoch 7/8\n",
      "500000/500000 [==============================] - 8s 15us/step - loss: 0.6929 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5139\n",
      "Epoch 8/8\n",
      "500000/500000 [==============================] - 7s 14us/step - loss: 0.6929 - acc: 0.5120 - val_loss: 0.6927 - val_acc: 0.5139\n",
      "{'optimizer': 'rmsprop', 'nrCamadas': 1, 'epochs': 4, 'batch_size': 256, 'ativacao': 'tanh', 'topologia': [64]}\n",
      "Train on 500000 samples, validate on 50000 samples\n",
      "Epoch 1/4\n",
      "500000/500000 [==============================] - 3s 5us/step - loss: 0.6930 - acc: 0.5092 - val_loss: 0.6927 - val_acc: 0.5107\n",
      "Epoch 2/4\n",
      "500000/500000 [==============================] - 2s 4us/step - loss: 0.6930 - acc: 0.5102 - val_loss: 0.6933 - val_acc: 0.5129\n",
      "Epoch 3/4\n",
      "500000/500000 [==============================] - 2s 4us/step - loss: 0.6930 - acc: 0.5106 - val_loss: 0.6931 - val_acc: 0.5016\n",
      "Epoch 4/4\n",
      "500000/500000 [==============================] - 2s 4us/step - loss: 0.6929 - acc: 0.5105 - val_loss: 0.6928 - val_acc: 0.5089\n",
      "{'optimizer': 'adam', 'nrCamadas': 2, 'epochs': 8, 'batch_size': 64, 'ativacao': 'tanh', 'topologia': [16, 5]}\n",
      "Train on 500000 samples, validate on 50000 samples\n",
      "Epoch 1/8\n",
      "500000/500000 [==============================] - 8s 16us/step - loss: 0.6930 - acc: 0.5100 - val_loss: 0.6929 - val_acc: 0.5098\n",
      "Epoch 2/8\n",
      "500000/500000 [==============================] - 7s 15us/step - loss: 0.6929 - acc: 0.5111 - val_loss: 0.6927 - val_acc: 0.5145\n",
      "Epoch 3/8\n",
      "500000/500000 [==============================] - 7s 15us/step - loss: 0.6928 - acc: 0.5114 - val_loss: 0.6927 - val_acc: 0.5107\n",
      "Epoch 4/8\n",
      "500000/500000 [==============================] - 7s 15us/step - loss: 0.6928 - acc: 0.5125 - val_loss: 0.6928 - val_acc: 0.5145\n",
      "Epoch 5/8\n",
      "500000/500000 [==============================] - 7s 15us/step - loss: 0.6928 - acc: 0.5122 - val_loss: 0.6927 - val_acc: 0.5145\n",
      "Epoch 6/8\n",
      "500000/500000 [==============================] - 8s 15us/step - loss: 0.6928 - acc: 0.5128 - val_loss: 0.6928 - val_acc: 0.5129\n",
      "Epoch 7/8\n",
      "500000/500000 [==============================] - 8s 16us/step - loss: 0.6928 - acc: 0.5121 - val_loss: 0.6927 - val_acc: 0.5145\n",
      "Epoch 8/8\n",
      "500000/500000 [==============================] - 7s 14us/step - loss: 0.6928 - acc: 0.5120 - val_loss: 0.6927 - val_acc: 0.5145\n"
     ]
    }
   ],
   "source": [
    "res = optimizacaoHyperParametros(dicionario,neuronios,\n",
    "                          trainX,trainY,\n",
    "                          valX,valY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ativacao</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>nrCamadas</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>score</th>\n",
       "      <th>topologia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>elu</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.517100</td>\n",
       "      <td>[16, 3, 10, 5, 4, 128, 128, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tanh</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.516647</td>\n",
       "      <td>[16, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tanh</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0.514918</td>\n",
       "      <td>[64]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tanh</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.512065</td>\n",
       "      <td>[10, 8, 10, 4, 64, 64]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ativacao  batch_size  epochs  nrCamadas optimizer     score  \\\n",
       "1      elu         128       8          8       sgd  0.517100   \n",
       "3     tanh          64       8          2      adam  0.516647   \n",
       "2     tanh         256       4          1   rmsprop  0.514918   \n",
       "0     tanh         128       8          6       sgd  0.512065   \n",
       "\n",
       "                        topologia  \n",
       "1  [16, 3, 10, 5, 4, 128, 128, 2]  \n",
       "3                         [16, 5]  \n",
       "2                            [64]  \n",
       "0          [10, 8, 10, 4, 64, 64]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado = pd.DataFrame(res)\n",
    "resultado.sort_values(by=['score'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'nrCamadas': 1, 'epochs': 20, 'batch_size': 128, 'ativacao': 'sigmoid', 'topologia': [10]}\n",
      "\n",
      "{'nrCamadas': 5, 'epochs': 8, 'batch_size': 512, 'ativacao': 'sigmoid', 'topologia': [8, 10, 4, 64, 64]}\n",
      "\n",
      "{'nrCamadas': 1, 'epochs': 8, 'batch_size': 256, 'ativacao': 'tanh', 'topologia': [16]}\n",
      "\n",
      "{'nrCamadas': 6, 'epochs': 4, 'batch_size': 256, 'ativacao': 'elu', 'topologia': [3, 10, 5, 4, 128, 128]}\n",
      "\n",
      "{'nrCamadas': 3, 'epochs': 8, 'batch_size': 256, 'ativacao': 'linear', 'topologia': [2, 64, 16]}\n",
      "\n",
      "{'nrCamadas': 4, 'epochs': 20, 'batch_size': 64, 'ativacao': 'relu', 'topologia': [5, 4, 16, 8]}\n",
      "\n",
      "{'nrCamadas': 6, 'epochs': 10, 'batch_size': 64, 'ativacao': 'exponential', 'topologia': [16, 16, 3, 32, 128, 128]}\n",
      "\n",
      "{'nrCamadas': 1, 'epochs': 4, 'batch_size': 256, 'ativacao': 'relu', 'topologia': [16]}\n",
      "\n",
      "{'nrCamadas': 1, 'epochs': 10, 'batch_size': 256, 'ativacao': 'linear', 'topologia': [2]}\n",
      "\n",
      "{'nrCamadas': 4, 'epochs': 20, 'batch_size': 256, 'ativacao': 'tanh', 'topologia': [2, 3, 128, 5]}\n"
     ]
    }
   ],
   "source": [
    "parametros = selecaoHyperParametros(dicionario,neuronios)\n",
    "for var in parametros:\n",
    "    print()\n",
    "    print(var)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
