{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relatório TP Parte II: Aprendizagem Automática 2\n",
    "## Microsoft Malware Prediction\n",
    " \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "- Carlos Gonçalves    a77278\n",
    "-  José Ferreira    a78452\n",
    "-  Ricardo Peixoto    a78587\n",
    "\n",
    "#### Mestrado Integrando em Engenharia Informática, Universidade do Minho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução\n",
    "\n",
    "Nesta fase do trabalho o objetivo passava pela utilização de métodos de *machine learning* considerados *deep*, em oposição aos métodos mais tradicionais utilizados na primeira fase, comparando a performance entre os diferentes modelos. Como este trabalho é uma continuidade da fase anterior existem certos tópicos que já foram tratados e não serão abordados novamente. Fazem parte desses assuntos a análise e tratamento dos dados recolhidos. \n",
    "Apesar disso o grupo sentiu que, com esta nova abordagem, era possível a utilização de uma maior quantidade de atributos. Assim sendo decidimos que, além do *dataset* utilizado na primeira fase, iriamos também extender esse *dataset* e utilizar adicionalmente algumas variáveis que foram desconsideradas anteriormente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variáveis reconsideradas\n",
    "\n",
    "![alt](img.png)\n",
    "\n",
    "Como podemos ver na imagem em cima apresentada, estas foram as variáveis eliminadas na primeira fase pelo excesso de atributos que continham.Isso deve-se ao facto de que os modelos tradicionais de *machine learning* não são propriamente eficientes com esta quantidade de dados. Isso já não se aplica a modelos de *deep learning* e por isso decidimos reaproveita-las para o treino e testes destes modelos. Devemos salientar que as variáveis apresentadas são todas categóricas pelo que com a codificação (*one-hot-encoding*) cada uma gera um número de atributos igual ao número de valores diferentes, levando à geração de bastantes atributos.\n",
    "\n",
    "Para reconsiderar estas variáveis era necessário o tratamento das mesmas, seguindo este uma abordagem semelhante à da primeira fase, que resumiremos de seguida.\n",
    "\n",
    "- Verificação de valores nulos\n",
    "- Substituição de valores nulos utilizando a seguinte técnica: verificamos a frequência de cada valor da coluna e caso esta seja superior a 94%, substituímos os NAs pelo valor modal. Caso contrário, prevemos o valor dos NAs.\n",
    "- Podiamos também analisar a possibilidade um agrupamento por classes\n",
    "- Após os passos anteriores era realizado o *one-hot-encoding* de cada variável\n",
    "\n",
    "Depois deste tratamento dos dados o objetivo seria a utilização do dataset inteiro e a utilização do dataset após a aplicação do *Variance Threshold*. \n",
    "Não foi possível realizar este objetivo por não dispormos de equipamento com recursos (memória,cpu) capazes de suportar um conjunto de dados com aquela dimensão. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimização de hiperparametros\n",
    "\n",
    "Nesta segunda fase decidimos apenas utilizar redes neuronais *feedforward*.  As redes *convolucionais* são mais adequadas a processamento de imagens, enquanto que as redes *recorrentes* são mais indicadas no processamento de sequencias, séries temporais,  texto e audio. Assim sendo o nosso objetivo foi focar-nos nas redes *feedforward* e na otimização dos seus hiperparametros. \n",
    "\n",
    "Os hiperparametros considerados foram os seguintes:\n",
    "- Topologia da rede\n",
    "- Early Stop\n",
    "- Dropout\n",
    "- Regularizers\n",
    "- Batch size\n",
    "- Epochs\n",
    "- Funções da ativação\n",
    "- Otimizadores\n",
    "\n",
    "Após alguma pesquisa nesta área estes foram os parametros que consideramos como os mais revelantes para o objetivo de aumentar a performance da rede. O mais importante é obviamente a topologia da rede e é este que possivelmente provoca alterações mais drásticas no comportamento do modelo. Seguem-se os algoritmos de treino e parâmetros de regularização(utilizados para combater o *overfitting*). Os seguintes são menos relevantes mas decidimos otimiza-los mesmo assim, dando-lhe menos importância.\n",
    "Tanto nos algoritmos de treino como nos otimizadores existem outros parâmetros que poderiam ser otimizados, no entanto, isso aumentaria ainda mais o espaço de procura pelo que decidimos não seguir essa abordagem.\n",
    "\n",
    "A otimização de hiperparâmetros foi realizada utilizando uma procura aleatória de N redes diferentes, sendo que definimos o N como quinze, para não potencializar o *bias* nos dados de validação.\n",
    "\n",
    "Aplicamos esta metedologia tanto ao *dataset* total como aos dados obtidos após a aplicação do filtro de variância.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimização de hyper-parâmetros\n",
    "\n",
    "A ideia é que esta função selecione um número X de diferentes redes.\n",
    "\n",
    "Depois vamos criar uma função que para cada rede, vai fazer o treino e testar o score com os dados de validação. Essa função depois ordena consoante o melhor valor de AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterSampler\n",
    "import random as r\n",
    "def selecaoHyperParametros(d,neuronios,nrCamadas,reg,n_it):\n",
    "    lista_parametros = list(ParameterSampler(d, n_iter=n_it, random_state=10))\n",
    "    r.seed(10)\n",
    "    i = 0\n",
    "    for var in lista_parametros:\n",
    "        var['nrCamadas'] = r.choice(nrCamadas)\n",
    "        \n",
    "        var['topologia'] = r.choices(neuronios,k=var['nrCamadas'])\n",
    "            \n",
    "        var['regularizer'] = r.choice([0,1,2,3])\n",
    "        aux = var['regularizer']\n",
    "        if aux == 1:\n",
    "            var['l1'] = r.choice(reg)\n",
    "        elif aux == 2:\n",
    "            var['l2'] = r.choice(reg)\n",
    "        elif aux == 3:\n",
    "            var['l1'] = r.choice(reg)\n",
    "            var['l2'] = r.choice(reg)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        while var in lista_parametros[:i]:\n",
    "            var['topologia'] = r.choices(neuronios,k=var['nrCamadas'])\n",
    "            aux = var['regularizer']\n",
    "            if aux == 1:\n",
    "                var['l1'] = r.choice(reg)\n",
    "            elif aux == 2:\n",
    "                var['l2'] = r.choice(reg)\n",
    "            elif aux == 3:\n",
    "                var['l1'] = r.choice(reg)\n",
    "                var['l2'] = r.choice(reg)\n",
    "            else:\n",
    "                pass\n",
    "        i+=1\n",
    "    return lista_parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função que cria uma rede consoante os parametros passados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import models,layers,regularizers\n",
    "def criaRede(param,inputSize):\n",
    "    model=models.Sequential()\n",
    "    aux = param['regularizer']\n",
    "    kernel_reg = None\n",
    "    if aux == 1:\n",
    "        kernel_reg = regularizers.l1(param['l1'])\n",
    "    elif aux == 2:\n",
    "        kernel_reg = regularizers.l2(param['l2'])\n",
    "    elif aux == 3:\n",
    "        kernel_reg = regularizers.l1_l2(l1=param['l1'],l2=param['l2'])\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    model.add(layers.Dense(param['topologia'][0],activation=param['ativacao'],\n",
    "                           kernel_regularizer=kernel_reg,input_shape=(inputSize,)))\n",
    "    if param['dropout'] > 0:\n",
    "        model.add(layers.Dropout(param['dropout']))\n",
    "    for var in param['topologia'][1:]:\n",
    "        model.add(layers.Dense(var,activation=param['ativacao'],kernel_regularizer=kernel_reg))\n",
    "        if param['dropout'] > 0:\n",
    "            model.add(layers.Dropout(param['dropout']))\n",
    "    model.add(layers.Dense(1,activation='sigmoid'))\n",
    "    model.compile(optimizer=param['optimizer'],\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função que cria uma lista de diferentes parametros a testar.\n",
    "\n",
    "Para cada um dos elementos da lista (parametros) cria uma rede e realiza o treino da mesma, calculando de seguida o *score*.\n",
    "\n",
    "Guarda todas as configurações juntamente com o *score* e retorna-as."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from keras.callbacks import EarlyStopping\n",
    "def optimizacaoHyperParametros(d,neuronios,nrCamadas,reg,trainX,trainY,valX,valY,n_it):\n",
    "    params = selecaoHyperParametros(d,neuronios,nrCamadas,reg,n_it)\n",
    "    for param in params:\n",
    "        rede = criaRede(param,trainX.shape[1])\n",
    "        if param['early_stopping'] > 0:\n",
    "            early = EarlyStopping(monitor='val_loss', patience=param['early_stopping'],\n",
    "                                  min_delta=0, verbose=True, mode='auto')\n",
    "            callb = [early]\n",
    "            history = rede.fit(trainX,\n",
    "                                trainY,\n",
    "                                epochs=param['epochs'],\n",
    "                                batch_size=param['batch_size'],\n",
    "                                validation_data=(valX,valY),\n",
    "                                callbacks=callb,\n",
    "                              verbose=False)\n",
    "        else:\n",
    "            history = rede.fit(trainX,\n",
    "                                trainY,\n",
    "                                epochs=param['epochs'],\n",
    "                                batch_size=param['batch_size'],\n",
    "                                validation_data=(valX,valY),\n",
    "                              verbose=False)\n",
    "        pred = rede.predict(valX)\n",
    "        false_positive_rate, true_positive_rate, thresholds = roc_curve(valY, pred)\n",
    "        score = auc(false_positive_rate, true_positive_rate)\n",
    "        param['score'] = score\n",
    "        print(param)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicionario = {\n",
    "    'ativacao':['relu','tanh','sigmoid','linear'],\n",
    "    'epochs':[10,20],\n",
    "    'batch_size':[64,128,256,512],\n",
    "    'optimizer':['rmsprop','adam','sgd'],\n",
    "    'dropout':[0.0,0.1,0.2,0.3,0.4],\n",
    "    'confs':[0,1,2,3],\n",
    "    'early_stopping':[0,4,5]\n",
    "}\n",
    "neuronios = [2,3,4,5,8,10,16,32,64]\n",
    "valores_l1 = [0.1,0.01,0.001] \n",
    "nrCamadas = [1,2,3,4,5,6,7,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "numericos = ['AVProductsInstalled',\n",
    "'AVProductsEnabled',\n",
    "'Census_ProcessorCoreCount',\n",
    "'Census_PrimaryDiskTotalCapacity',\n",
    "'Census_SystemVolumeTotalCapacity',\n",
    "'Census_TotalPhysicalRAM',\n",
    "'Census_InternalPrimaryDiagonalDisplaySizeInInches',\n",
    "'Census_InternalPrimaryDisplayResolutionHorizontal',\n",
    "'Census_InternalPrimaryDisplayResolutionVertical',\n",
    "'Census_InternalBatteryNumberOfCharges']\n",
    "dtype = {}\n",
    "for df in pd.read_csv('final_sembat.csv',low_memory=False,chunksize=10):\n",
    "    for var in df.columns:\n",
    "        if var not in numericos:\n",
    "            dtype[var] = 'int8'\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "auxPred = pd.DataFrame()\n",
    "i = 0\n",
    "for tp in pd.read_csv('final_sembat.csv',low_memory=False,chunksize=50000,dtype=dtype):\n",
    "    if i == 0:\n",
    "        auxPred = pd.concat([auxPred,tp])\n",
    "    else:\n",
    "        auxPred = pd.concat([auxPred,tp],ignore_index=True)\n",
    "    i+=1\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = auxPred.loc[:499999,auxPred.columns!='HasDetections']\n",
    "valX = auxPred.loc[500000:549999,auxPred.columns!='HasDetections']\n",
    "trainY = auxPred.loc[:499999,'HasDetections']\n",
    "valY = auxPred.loc[500000:549999,'HasDetections']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del auxPred\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 707)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 707)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtro de variância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import math\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "def realizaVarThreshold():\n",
    "    indices = []\n",
    "    col = trainX.columns\n",
    "    total = len(col)\n",
    "    chunk = math.floor(total / 10)\n",
    "    print(chunk)\n",
    "    quantos = 0\n",
    "    for i in range(chunk):\n",
    "        sel = VarianceThreshold(threshold=0.001)\n",
    "        try:\n",
    "            sel.fit(trainX[col[quantos:quantos+10]])\n",
    "            aux = [i+quantos for i in sel.get_support(indices=True)]\n",
    "            indices.extend(aux)\n",
    "        except:\n",
    "            pass\n",
    "        del sel\n",
    "        gc.collect()\n",
    "        quantos = quantos+10\n",
    "    sel = VarianceThreshold(threshold=0.001)\n",
    "    try:\n",
    "        sel.fit(trainX[col[quantos:quantos+7]])\n",
    "        indices.extend(sel.get_support(indices=True))\n",
    "    except:\n",
    "        pass\n",
    "    del sel\n",
    "    gc.collect()\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "indices = realizaVarThreshold()\n",
    "print(len(indices))\n",
    "col = []\n",
    "coln = trainX.columns\n",
    "for i in indices:\n",
    "       col.append(coln[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimização de hiper-parâmetros para os dados com o filtro de variância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jose/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/jose/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/jose/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 00006: early stopping\n",
      "{'optimizer': 'sgd', 'epochs': 20, 'early_stopping': 4, 'dropout': 0.1, 'confs': 2, 'batch_size': 512, 'ativacao': 'relu', 'nrCamadas': 1, 'topologia': [5], 'regularizer': 0, 'score': 0.5}\n",
      "Epoch 00006: early stopping\n",
      "{'optimizer': 'rmsprop', 'epochs': 20, 'early_stopping': 5, 'dropout': 0.1, 'confs': 3, 'batch_size': 64, 'ativacao': 'linear', 'nrCamadas': 4, 'topologia': [8, 8, 4, 32], 'regularizer': 0, 'score': 0.5088344840850655}\n",
      "Epoch 00010: early stopping\n",
      "{'optimizer': 'rmsprop', 'epochs': 10, 'early_stopping': 5, 'dropout': 0.4, 'confs': 2, 'batch_size': 512, 'ativacao': 'relu', 'nrCamadas': 8, 'topologia': [4, 4, 64, 64, 2, 32, 10, 5], 'regularizer': 2, 'l2': 0.001, 'score': 0.5}\n",
      "{'optimizer': 'rmsprop', 'epochs': 20, 'early_stopping': 0, 'dropout': 0.1, 'confs': 2, 'batch_size': 128, 'ativacao': 'sigmoid', 'nrCamadas': 5, 'topologia': [8, 16, 10, 3, 16], 'regularizer': 1, 'l1': 0.01, 'score': 0.5}\n",
      "{'optimizer': 'adam', 'epochs': 20, 'early_stopping': 4, 'dropout': 0.0, 'confs': 1, 'batch_size': 512, 'ativacao': 'relu', 'nrCamadas': 7, 'topologia': [2, 2, 3, 64, 4, 5, 64], 'regularizer': 2, 'l2': 0.001, 'score': 0.5}\n",
      "{'optimizer': 'sgd', 'epochs': 20, 'early_stopping': 4, 'dropout': 0.1, 'confs': 2, 'batch_size': 128, 'ativacao': 'tanh', 'nrCamadas': 8, 'topologia': [5, 2, 10, 32, 3, 4, 5, 2], 'regularizer': 3, 'l1': 0.01, 'l2': 0.001, 'score': 0.5}\n",
      "{'optimizer': 'sgd', 'epochs': 20, 'early_stopping': 0, 'dropout': 0.3, 'confs': 1, 'batch_size': 128, 'ativacao': 'linear', 'nrCamadas': 2, 'topologia': [8, 32], 'regularizer': 1, 'l1': 0.01, 'score': 0.5}\n",
      "{'optimizer': 'sgd', 'epochs': 10, 'early_stopping': 4, 'dropout': 0.4, 'confs': 0, 'batch_size': 64, 'ativacao': 'tanh', 'nrCamadas': 6, 'topologia': [64, 3, 64, 16, 5, 64], 'regularizer': 1, 'l1': 0.01, 'score': 0.5}\n",
      "{'optimizer': 'sgd', 'epochs': 20, 'early_stopping': 0, 'dropout': 0.3, 'confs': 1, 'batch_size': 128, 'ativacao': 'tanh', 'nrCamadas': 7, 'topologia': [64, 8, 16, 3, 8, 32, 4], 'regularizer': 2, 'l2': 0.1, 'score': 0.5}\n",
      "Epoch 00007: early stopping\n",
      "{'optimizer': 'sgd', 'epochs': 10, 'early_stopping': 4, 'dropout': 0.3, 'confs': 2, 'batch_size': 128, 'ativacao': 'tanh', 'nrCamadas': 3, 'topologia': [16, 8, 5], 'regularizer': 3, 'l1': 0.1, 'l2': 0.1, 'score': 0.5284982131775737}\n",
      "Epoch 00007: early stopping\n",
      "{'optimizer': 'rmsprop', 'epochs': 10, 'early_stopping': 4, 'dropout': 0.2, 'confs': 3, 'batch_size': 256, 'ativacao': 'relu', 'nrCamadas': 1, 'topologia': [4], 'regularizer': 2, 'l2': 0.1, 'score': 0.4992806364673663}\n",
      "Epoch 00006: early stopping\n",
      "{'optimizer': 'sgd', 'epochs': 20, 'early_stopping': 5, 'dropout': 0.0, 'confs': 0, 'batch_size': 512, 'ativacao': 'relu', 'nrCamadas': 2, 'topologia': [4, 5], 'regularizer': 1, 'l1': 0.01, 'score': 0.5}\n",
      "Epoch 00010: early stopping\n",
      "{'optimizer': 'sgd', 'epochs': 10, 'early_stopping': 5, 'dropout': 0.4, 'confs': 1, 'batch_size': 512, 'ativacao': 'sigmoid', 'nrCamadas': 8, 'topologia': [16, 4, 8, 64, 8, 10, 2, 8], 'regularizer': 3, 'l1': 0.01, 'l2': 0.1, 'score': 0.5}\n",
      "Epoch 00006: early stopping\n",
      "{'optimizer': 'rmsprop', 'epochs': 10, 'early_stopping': 5, 'dropout': 0.1, 'confs': 0, 'batch_size': 512, 'ativacao': 'tanh', 'nrCamadas': 7, 'topologia': [8, 5, 5, 16, 10, 2, 64], 'regularizer': 0, 'score': 0.5088207632787209}\n",
      "Epoch 00006: early stopping\n",
      "{'optimizer': 'sgd', 'epochs': 10, 'early_stopping': 5, 'dropout': 0.3, 'confs': 2, 'batch_size': 512, 'ativacao': 'linear', 'nrCamadas': 1, 'topologia': [5], 'regularizer': 0, 'score': 0.5}\n"
     ]
    }
   ],
   "source": [
    "res = optimizacaoHyperParametros(dicionario,neuronios,nrCamadas,valores_l1,\n",
    "                          trainX[col],trainY,\n",
    "                          valX[col],valY,\n",
    "                                15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ativacao</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>confs</th>\n",
       "      <th>dropout</th>\n",
       "      <th>early_stopping</th>\n",
       "      <th>epochs</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "      <th>nrCamadas</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>regularizer</th>\n",
       "      <th>score</th>\n",
       "      <th>topologia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tanh</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.100</td>\n",
       "      <td>3</td>\n",
       "      <td>sgd</td>\n",
       "      <td>3</td>\n",
       "      <td>0.528498</td>\n",
       "      <td>[16, 8, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linear</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0</td>\n",
       "      <td>0.508834</td>\n",
       "      <td>[8, 8, 4, 32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tanh</td>\n",
       "      <td>512</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0</td>\n",
       "      <td>0.508821</td>\n",
       "      <td>[8, 5, 5, 16, 10, 2, 64]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relu</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relu</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[4, 4, 64, 64, 2, 32, 10, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[8, 16, 10, 3, 16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>relu</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>7</td>\n",
       "      <td>adam</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[2, 2, 3, 64, 4, 5, 64]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tanh</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>sgd</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[5, 2, 10, 32, 3, 4, 5, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>linear</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>sgd</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[8, 32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tanh</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>sgd</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[64, 3, 64, 16, 5, 64]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tanh</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100</td>\n",
       "      <td>7</td>\n",
       "      <td>sgd</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[64, 8, 16, 3, 8, 32, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>relu</td>\n",
       "      <td>512</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>sgd</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[4, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.100</td>\n",
       "      <td>8</td>\n",
       "      <td>sgd</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[16, 4, 8, 64, 8, 10, 2, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>linear</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>2</td>\n",
       "      <td>0.499281</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ativacao  batch_size  confs  dropout  early_stopping  epochs    l1     l2  \\\n",
       "9      tanh         128      2      0.3               4      10  0.10  0.100   \n",
       "1    linear          64      3      0.1               5      20   NaN    NaN   \n",
       "13     tanh         512      0      0.1               5      10   NaN    NaN   \n",
       "0      relu         512      2      0.1               4      20   NaN    NaN   \n",
       "2      relu         512      2      0.4               5      10   NaN  0.001   \n",
       "3   sigmoid         128      2      0.1               0      20  0.01    NaN   \n",
       "4      relu         512      1      0.0               4      20   NaN  0.001   \n",
       "5      tanh         128      2      0.1               4      20  0.01  0.001   \n",
       "6    linear         128      1      0.3               0      20  0.01    NaN   \n",
       "7      tanh          64      0      0.4               4      10  0.01    NaN   \n",
       "8      tanh         128      1      0.3               0      20   NaN  0.100   \n",
       "11     relu         512      0      0.0               5      20  0.01    NaN   \n",
       "12  sigmoid         512      1      0.4               5      10  0.01  0.100   \n",
       "14   linear         512      2      0.3               5      10   NaN    NaN   \n",
       "10     relu         256      3      0.2               4      10   NaN  0.100   \n",
       "\n",
       "    nrCamadas optimizer  regularizer     score                     topologia  \n",
       "9           3       sgd            3  0.528498                    [16, 8, 5]  \n",
       "1           4   rmsprop            0  0.508834                 [8, 8, 4, 32]  \n",
       "13          7   rmsprop            0  0.508821      [8, 5, 5, 16, 10, 2, 64]  \n",
       "0           1       sgd            0  0.500000                           [5]  \n",
       "2           8   rmsprop            2  0.500000  [4, 4, 64, 64, 2, 32, 10, 5]  \n",
       "3           5   rmsprop            1  0.500000            [8, 16, 10, 3, 16]  \n",
       "4           7      adam            2  0.500000       [2, 2, 3, 64, 4, 5, 64]  \n",
       "5           8       sgd            3  0.500000    [5, 2, 10, 32, 3, 4, 5, 2]  \n",
       "6           2       sgd            1  0.500000                       [8, 32]  \n",
       "7           6       sgd            1  0.500000        [64, 3, 64, 16, 5, 64]  \n",
       "8           7       sgd            2  0.500000      [64, 8, 16, 3, 8, 32, 4]  \n",
       "11          2       sgd            1  0.500000                        [4, 5]  \n",
       "12          8       sgd            3  0.500000   [16, 4, 8, 64, 8, 10, 2, 8]  \n",
       "14          1       sgd            0  0.500000                           [5]  \n",
       "10          1   rmsprop            2  0.499281                           [4]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado = pd.DataFrame(res)\n",
    "resultado.sort_values(by=['score'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "427.900328"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(trainY.memory_usage() + valY.memory_usage() + \n",
    " trainX.memory_usage().sum() + valX.memory_usage().sum()) / (1000*1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimização de hiper-parâmetros para os dados totais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00005: early stopping\n",
      "{'optimizer': 'sgd', 'epochs': 20, 'early_stopping': 4, 'dropout': 0.1, 'confs': 2, 'batch_size': 512, 'ativacao': 'relu', 'nrCamadas': 1, 'topologia': [5], 'regularizer': 0, 'score': 0.5}\n",
      "Epoch 00007: early stopping\n",
      "{'optimizer': 'rmsprop', 'epochs': 20, 'early_stopping': 5, 'dropout': 0.1, 'confs': 3, 'batch_size': 64, 'ativacao': 'linear', 'nrCamadas': 4, 'topologia': [8, 8, 4, 32], 'regularizer': 0, 'score': 0.5}\n",
      "Epoch 00008: early stopping\n",
      "{'optimizer': 'rmsprop', 'epochs': 10, 'early_stopping': 5, 'dropout': 0.4, 'confs': 2, 'batch_size': 512, 'ativacao': 'relu', 'nrCamadas': 8, 'topologia': [4, 4, 64, 64, 2, 32, 10, 5], 'regularizer': 2, 'l2': 0.001, 'score': 0.5}\n",
      "{'optimizer': 'rmsprop', 'epochs': 20, 'early_stopping': 0, 'dropout': 0.1, 'confs': 2, 'batch_size': 128, 'ativacao': 'sigmoid', 'nrCamadas': 5, 'topologia': [8, 16, 10, 3, 16], 'regularizer': 1, 'l1': 0.01, 'score': 0.5}\n",
      "Epoch 00010: early stopping\n",
      "{'optimizer': 'adam', 'epochs': 20, 'early_stopping': 4, 'dropout': 0.0, 'confs': 1, 'batch_size': 512, 'ativacao': 'relu', 'nrCamadas': 7, 'topologia': [2, 2, 3, 64, 4, 5, 64], 'regularizer': 2, 'l2': 0.001, 'score': 0.4933295785155971}\n",
      "Epoch 00015: early stopping\n",
      "{'optimizer': 'sgd', 'epochs': 20, 'early_stopping': 4, 'dropout': 0.1, 'confs': 2, 'batch_size': 128, 'ativacao': 'tanh', 'nrCamadas': 8, 'topologia': [5, 2, 10, 32, 3, 4, 5, 2], 'regularizer': 3, 'l1': 0.01, 'l2': 0.001, 'score': 0.5}\n",
      "{'optimizer': 'sgd', 'epochs': 20, 'early_stopping': 0, 'dropout': 0.3, 'confs': 1, 'batch_size': 128, 'ativacao': 'linear', 'nrCamadas': 2, 'topologia': [8, 32], 'regularizer': 1, 'l1': 0.01, 'score': 0.5}\n",
      "{'optimizer': 'sgd', 'epochs': 10, 'early_stopping': 4, 'dropout': 0.4, 'confs': 0, 'batch_size': 64, 'ativacao': 'tanh', 'nrCamadas': 6, 'topologia': [64, 3, 64, 16, 5, 64], 'regularizer': 1, 'l1': 0.01, 'score': 0.5}\n",
      "{'optimizer': 'sgd', 'epochs': 20, 'early_stopping': 0, 'dropout': 0.3, 'confs': 1, 'batch_size': 128, 'ativacao': 'tanh', 'nrCamadas': 7, 'topologia': [64, 8, 16, 3, 8, 32, 4], 'regularizer': 2, 'l2': 0.1, 'score': 0.5}\n",
      "Epoch 00010: early stopping\n",
      "{'optimizer': 'sgd', 'epochs': 10, 'early_stopping': 4, 'dropout': 0.3, 'confs': 2, 'batch_size': 128, 'ativacao': 'tanh', 'nrCamadas': 3, 'topologia': [16, 8, 5], 'regularizer': 3, 'l1': 0.1, 'l2': 0.1, 'score': 0.4933184145104349}\n",
      "Epoch 00010: early stopping\n",
      "{'optimizer': 'rmsprop', 'epochs': 10, 'early_stopping': 4, 'dropout': 0.2, 'confs': 3, 'batch_size': 256, 'ativacao': 'relu', 'nrCamadas': 1, 'topologia': [4], 'regularizer': 2, 'l2': 0.1, 'score': 0.49116551591493457}\n",
      "{'optimizer': 'sgd', 'epochs': 20, 'early_stopping': 5, 'dropout': 0.0, 'confs': 0, 'batch_size': 512, 'ativacao': 'relu', 'nrCamadas': 2, 'topologia': [4, 5], 'regularizer': 1, 'l1': 0.01, 'score': 0.5}\n",
      "{'optimizer': 'sgd', 'epochs': 10, 'early_stopping': 5, 'dropout': 0.4, 'confs': 1, 'batch_size': 512, 'ativacao': 'sigmoid', 'nrCamadas': 8, 'topologia': [16, 4, 8, 64, 8, 10, 2, 8], 'regularizer': 3, 'l1': 0.01, 'l2': 0.1, 'score': 0.5}\n",
      "{'optimizer': 'rmsprop', 'epochs': 10, 'early_stopping': 5, 'dropout': 0.1, 'confs': 0, 'batch_size': 512, 'ativacao': 'tanh', 'nrCamadas': 7, 'topologia': [8, 5, 5, 16, 10, 2, 64], 'regularizer': 0, 'score': 0.5276764831976059}\n",
      "Epoch 00006: early stopping\n",
      "{'optimizer': 'sgd', 'epochs': 10, 'early_stopping': 5, 'dropout': 0.3, 'confs': 2, 'batch_size': 512, 'ativacao': 'linear', 'nrCamadas': 1, 'topologia': [5], 'regularizer': 0, 'score': 0.5088344840850655}\n"
     ]
    }
   ],
   "source": [
    "res = optimizacaoHyperParametros(dicionario,neuronios,nrCamadas,valores_l1,\n",
    "                          trainX[:300000],trainY[:300000],\n",
    "                          valX,valY,\n",
    "                                15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ativacao</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>confs</th>\n",
       "      <th>dropout</th>\n",
       "      <th>early_stopping</th>\n",
       "      <th>epochs</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "      <th>nrCamadas</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>regularizer</th>\n",
       "      <th>score</th>\n",
       "      <th>topologia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tanh</td>\n",
       "      <td>512</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0</td>\n",
       "      <td>0.527676</td>\n",
       "      <td>[8, 5, 5, 16, 10, 2, 64]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>linear</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0</td>\n",
       "      <td>0.508834</td>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relu</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linear</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[8, 8, 4, 32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relu</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[4, 4, 64, 64, 2, 32, 10, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[8, 16, 10, 3, 16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tanh</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>sgd</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[5, 2, 10, 32, 3, 4, 5, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>linear</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>sgd</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[8, 32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tanh</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>sgd</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[64, 3, 64, 16, 5, 64]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tanh</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100</td>\n",
       "      <td>7</td>\n",
       "      <td>sgd</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[64, 8, 16, 3, 8, 32, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>relu</td>\n",
       "      <td>512</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>sgd</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[4, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.100</td>\n",
       "      <td>8</td>\n",
       "      <td>sgd</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[16, 4, 8, 64, 8, 10, 2, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>relu</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>7</td>\n",
       "      <td>adam</td>\n",
       "      <td>2</td>\n",
       "      <td>0.493330</td>\n",
       "      <td>[2, 2, 3, 64, 4, 5, 64]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tanh</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.100</td>\n",
       "      <td>3</td>\n",
       "      <td>sgd</td>\n",
       "      <td>3</td>\n",
       "      <td>0.493318</td>\n",
       "      <td>[16, 8, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>2</td>\n",
       "      <td>0.491166</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ativacao  batch_size  confs  dropout  early_stopping  epochs    l1     l2  \\\n",
       "13     tanh         512      0      0.1               5      10   NaN    NaN   \n",
       "14   linear         512      2      0.3               5      10   NaN    NaN   \n",
       "0      relu         512      2      0.1               4      20   NaN    NaN   \n",
       "1    linear          64      3      0.1               5      20   NaN    NaN   \n",
       "2      relu         512      2      0.4               5      10   NaN  0.001   \n",
       "3   sigmoid         128      2      0.1               0      20  0.01    NaN   \n",
       "5      tanh         128      2      0.1               4      20  0.01  0.001   \n",
       "6    linear         128      1      0.3               0      20  0.01    NaN   \n",
       "7      tanh          64      0      0.4               4      10  0.01    NaN   \n",
       "8      tanh         128      1      0.3               0      20   NaN  0.100   \n",
       "11     relu         512      0      0.0               5      20  0.01    NaN   \n",
       "12  sigmoid         512      1      0.4               5      10  0.01  0.100   \n",
       "4      relu         512      1      0.0               4      20   NaN  0.001   \n",
       "9      tanh         128      2      0.3               4      10  0.10  0.100   \n",
       "10     relu         256      3      0.2               4      10   NaN  0.100   \n",
       "\n",
       "    nrCamadas optimizer  regularizer     score                     topologia  \n",
       "13          7   rmsprop            0  0.527676      [8, 5, 5, 16, 10, 2, 64]  \n",
       "14          1       sgd            0  0.508834                           [5]  \n",
       "0           1       sgd            0  0.500000                           [5]  \n",
       "1           4   rmsprop            0  0.500000                 [8, 8, 4, 32]  \n",
       "2           8   rmsprop            2  0.500000  [4, 4, 64, 64, 2, 32, 10, 5]  \n",
       "3           5   rmsprop            1  0.500000            [8, 16, 10, 3, 16]  \n",
       "5           8       sgd            3  0.500000    [5, 2, 10, 32, 3, 4, 5, 2]  \n",
       "6           2       sgd            1  0.500000                       [8, 32]  \n",
       "7           6       sgd            1  0.500000        [64, 3, 64, 16, 5, 64]  \n",
       "8           7       sgd            2  0.500000      [64, 8, 16, 3, 8, 32, 4]  \n",
       "11          2       sgd            1  0.500000                        [4, 5]  \n",
       "12          8       sgd            3  0.500000   [16, 4, 8, 64, 8, 10, 2, 8]  \n",
       "4           7      adam            2  0.493330       [2, 2, 3, 64, 4, 5, 64]  \n",
       "9           3       sgd            3  0.493318                    [16, 8, 5]  \n",
       "10          1   rmsprop            2  0.491166                           [4]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado = pd.DataFrame(res)\n",
    "resultado.sort_values(by=['score'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleção do melhor modelo\n",
    "Como podemos ver nas tabelas acima o melhor modelo nos dados de validação foi o modelo que contém as seguintes caraterísticas:\n",
    "- topologia: [16, 8, 5]\n",
    "- função de ativação: tanh\n",
    "- batch_size: 128\n",
    "- dropout: 0.3\n",
    "-early_stopping: 4\n",
    "- epochs: 10\n",
    "- regularizers:\n",
    "    - l1: 0.1\n",
    "    - l2: 0.1\n",
    "- optimizer: sgd (Gradiente descendente estocástico)\n",
    "\n",
    "Para além disso este modelo usa apenas as colunas que passam no filtro de variância.\n",
    "\n",
    "Este modelo obteve um score de 0.528498 (AUC)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregar os dados para testar o erro nos dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "auxPred = pd.DataFrame()\n",
    "i = 0\n",
    "for tp in pd.read_csv('final_sembat.csv',low_memory=False,chunksize=50000,dtype=dtype):\n",
    "    if i == 0:\n",
    "        auxPred = pd.concat([auxPred,tp])\n",
    "    else:\n",
    "        auxPred = pd.concat([auxPred,tp],ignore_index=True)\n",
    "    i+=1\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainX = auxPred.loc[:499999,auxPred.columns!='HasDetections']\n",
    "valX = auxPred.loc[500000:549999,auxPred.columns!='HasDetections']\n",
    "trainY = auxPred.loc[:499999,'HasDetections']\n",
    "valY = auxPred.loc[500000:549999,'HasDetections']\n",
    "testX = auxPred.loc[550000:599999,auxPred.columns!='HasDetections']\n",
    "testY = auxPred.loc[550000:599999,'HasDetections']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del auxPred\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'optimizer': 'sgd', 'epochs': 10, 'early_stopping': 4, \n",
    "          'dropout': 0.3, 'confs': 2, 'batch_size': 128, 'ativacao': 'tanh', 'nrCamadas': 3, \n",
    "          'topologia': [16, 8, 5], 'regularizer': 3, 'l1': 0.1, 'l2': 0.1}\n",
    "rede = criaRede(params,trainX[col].shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criar a rede com a melhor configuração e treinar a mesma da mesma forma que foi realizada anteriormente.\n",
    "\n",
    "Depois é verificado o score nos dados de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500000 samples, validate on 50000 samples\n",
      "Epoch 1/10\n",
      "500000/500000 [==============================] - 19s 39us/step - loss: 1.5895 - acc: 0.5017 - val_loss: 0.9419 - val_acc: 0.4997\n",
      "Epoch 2/10\n",
      "500000/500000 [==============================] - 16s 33us/step - loss: 0.9419 - acc: 0.4999 - val_loss: 0.9420 - val_acc: 0.4997\n",
      "Epoch 3/10\n",
      "500000/500000 [==============================] - 16s 33us/step - loss: 0.9419 - acc: 0.4983 - val_loss: 0.9420 - val_acc: 0.4997\n",
      "Epoch 4/10\n",
      "500000/500000 [==============================] - 17s 33us/step - loss: 0.9419 - acc: 0.5002 - val_loss: 0.9419 - val_acc: 0.4997\n",
      "Epoch 5/10\n",
      "500000/500000 [==============================] - 16s 33us/step - loss: 0.9419 - acc: 0.4993 - val_loss: 0.9420 - val_acc: 0.5003\n",
      "Epoch 6/10\n",
      "500000/500000 [==============================] - 16s 33us/step - loss: 0.9419 - acc: 0.4990 - val_loss: 0.9419 - val_acc: 0.5003\n",
      "Epoch 7/10\n",
      "500000/500000 [==============================] - 16s 33us/step - loss: 0.9419 - acc: 0.4998 - val_loss: 0.9419 - val_acc: 0.4997\n",
      "Epoch 8/10\n",
      "500000/500000 [==============================] - 16s 33us/step - loss: 0.9419 - acc: 0.4993 - val_loss: 0.9419 - val_acc: 0.4997\n",
      "Epoch 9/10\n",
      "500000/500000 [==============================] - 16s 32us/step - loss: 0.9419 - acc: 0.4999 - val_loss: 0.9420 - val_acc: 0.5003\n",
      "Epoch 10/10\n",
      "500000/500000 [==============================] - 16s 33us/step - loss: 0.9419 - acc: 0.4995 - val_loss: 0.9419 - val_acc: 0.4997\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "if params['early_stopping'] > 0:\n",
    "    early = EarlyStopping(monitor='val_loss', patience=params['early_stopping'],\n",
    "                          min_delta=0, verbose=True, mode='auto')\n",
    "    callb = [early]\n",
    "    history = rede.fit(trainX[col],\n",
    "                        trainY,\n",
    "                        epochs=params['epochs'],\n",
    "                        batch_size=params['batch_size'],\n",
    "                        validation_data=(valX[col],valY),\n",
    "                        callbacks=callb)\n",
    "else:\n",
    "    history = rede.fit(trainX[col],\n",
    "                        trainY,\n",
    "                        epochs=params['epochs'],\n",
    "                        batch_size=params['batch_size'],\n",
    "                        validation_data=(valX[col],valY))\n",
    "pred = rede.predict(testX[col])\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(testY, pred)\n",
    "score = auc(false_positive_rate, true_positive_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score final do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5010305127845165"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusão\n",
    "\n",
    "Como foi referido anteriormente o objetivo da segunda fase passava por aplicar métodos de aprendizagem máquina *deep* e comparar o resultado obtido com o resultada da fase transata. Nesta fase o foco recaiu sobre as redes neuronais sendo que o aspeto que foi intensamente abordado foi a otimização dos hiper-parametros dessas mesmas redes. Através dessa otimização foi-nos possível criar e testar uma quantidade muito significativa de redes diferentes, com caracteristicas bastantes diversas. \n",
    "\n",
    "Como pudemos verificar os resultados obtidos não foram os esperados, visto serem inferiores aos apurados com os métodos tradicionais, sendo que essa diferença é bastante considerável tendo um **score** de 0.5010305127845165 neste modelo quando tinha sido de 0.6634414889076333 para o melhor modelo na fase anterior.\n",
    "\n",
    "Aquilo que poderiamos ter realizado e que poderia potencializar um maior acerto, foi como já referimos, a utilização de mais atributos ou até mesmo a utilização de um diferente tipo de rede. Mesmo assim não achamos que os resultados iriam melhorar de forma significativa com a adoção destas medidas. \n",
    "\n",
    "Um problema que o grupo não conseguiu resolver foi que a métrica usada para monitorizar o *EarlyStopping* foi a loss nos casos de validação, no entanto esta métrica não é a utilizada para avaliar o modelo. Idealmente seria usado o **AUC** como monitor, no entanto não conseguimos aplicar o cálculo do mesmo em *batches*, sendo algo que pode ser melhorado e pode melhorar os resultados.\n",
    "\n",
    "No final podemos concluir que o melhor modelo foi o obtido na primeira fase o que nos leva a perceber que apesar destes novos métodos parecerem mais robustos quando comparados com os métodos mais tradicionais, isso não é uma verdade absoluta. O que podemos perceber é que cada método pode ser mais apropriado para um determinado caso, não existindo um melhor ou que se comporte aproximadamente bem em todos os casos. No nosso exemplo o mais apropriado é um método de *machine learning* tradicional, as **Random Forests**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
