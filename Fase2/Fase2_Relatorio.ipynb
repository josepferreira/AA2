{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimização de hyper-parâmetros\n",
    "\n",
    "A ideia é que esta função selecione um número X de diferentes redes.\n",
    "\n",
    "Depois vamos criar uma função que para cada rede, vai fazer o treino e testar o score com os dados de validação. Essa função depois ordena consoante o melhor valor de AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterSampler\n",
    "import random as r\n",
    "def selecaoHyperParametros(d,neuronios,reg):\n",
    "    lista_parametros = list(ParameterSampler(d, n_iter=10, random_state=10))\n",
    "    r.seed(10)\n",
    "    for var in lista_parametros:\n",
    "        var['topologia'] = r.choices(neuronios,k=var['nrCamadas'])\n",
    "        aux = var['regularizer']\n",
    "        if aux == 1:\n",
    "            var['l1'] = r.choice(reg)\n",
    "        elif aux == 2:\n",
    "            var['l2'] = r.choice(reg)\n",
    "        elif aux == 3:\n",
    "            var['l1'] = r.choice(reg)\n",
    "            var['l2'] = r.choice(reg)\n",
    "        else:\n",
    "            pass\n",
    "    return lista_parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import models,layers,regularizers\n",
    "def criaRede(param,inputSize):\n",
    "    model=models.Sequential()\n",
    "    aux = param['regularizer']\n",
    "    kernel_reg = None\n",
    "    '''if aux == 1:\n",
    "        kernel_reg = regularizers.l1(param['l1'])\n",
    "    elif aux == 2:\n",
    "        kernel_reg = regularizers.l2(param['l2'])\n",
    "    elif aux == 3:\n",
    "        kernel_reg = regularizers.l1_l2(l1=param['l1'],l2=param['l2'])\n",
    "    else:\n",
    "        pass '''\n",
    "    \n",
    "    model.add(layers.Dense(param['topologia'][0],activation=param['ativacao'],\n",
    "                           kernel_regularizer=kernel_reg,input_shape=(inputSize,)))\n",
    "    if param['dropout'] > 0:\n",
    "        model.add(layers.Dropout(param['dropout']))\n",
    "    for var in param['topologia'][1:]:\n",
    "        model.add(layers.Dense(var,activation=param['ativacao'],kernel_regularizer=kernel_reg))\n",
    "        if param['dropout'] > 0:\n",
    "            model.add(layers.Dropout(param['dropout']))\n",
    "    model.add(layers.Dense(1,activation='sigmoid'))\n",
    "    model.compile(optimizer=param['optimizer'],\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from keras.callbacks import EarlyStopping\n",
    "def optimizacaoHyperParametros(d,neuronios,reg,trainX,trainY,valX,valY):\n",
    "    params = selecaoHyperParametros(d,neuronios,reg)\n",
    "    for param in params:\n",
    "        print(param)\n",
    "        rede = criaRede(param,trainX.shape[1])\n",
    "        if param['early_stopping'] > 0:\n",
    "            early = EarlyStopping(monitor='val_loss', patience=param['early_stopping'],\n",
    "                                  min_delta=0, verbose=True, mode='auto')\n",
    "            callb = [early]\n",
    "            history = rede.fit(trainX,\n",
    "                                trainY,\n",
    "                                epochs=param['epochs'],\n",
    "                                batch_size=param['batch_size'],\n",
    "                                validation_data=(valX,valY),\n",
    "                                callbacks=callb)\n",
    "        else:\n",
    "            history = rede.fit(trainX,\n",
    "                                trainY,\n",
    "                                epochs=param['epochs'],\n",
    "                                batch_size=param['batch_size'],\n",
    "                                validation_data=(valX,valY))\n",
    "        pred = rede.predict(valX)\n",
    "        false_positive_rate, true_positive_rate, thresholds = roc_curve(valY, pred)\n",
    "        score = auc(false_positive_rate, true_positive_rate)\n",
    "        param['score'] = score\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aqui estão os parametros que vamos optimizar\n",
    "\n",
    "### Faltam ainda ver o dropout, early stopping e regularização\n",
    "\n",
    "### Optimizer temos de ver os parâmetros existentes também:\n",
    "- rmsprop\n",
    "    - rho: float >= 0.\n",
    "    - epsilon: float >= 0. Fuzz factor. If None, defaults to K.epsilon().\n",
    "    - decay: float >= 0. Learning rate decay over each update.\n",
    "- SGD\n",
    "    - momentum: float >= 0. Parameter that accelerates SGD in the relevant direction and dampens oscillations.\n",
    "    - decay: float >= 0. Learning rate decay over each update.\n",
    "    - nesterov: boolean. Whether to apply Nesterov momentum.\n",
    "- Adam\n",
    "    - beta_1: float, 0 < beta < 1. Generally close to 1.\n",
    "    - beta_2: float, 0 < beta < 1. Generally close to 1.\n",
    "    - epsilon: float >= 0. Fuzz factor. If None, defaults to K.epsilon().\n",
    "    - decay: float >= 0. Learning rate decay over each update.\n",
    "    - amsgrad: boolean. Whether to apply the AMSGrad variant of this algorithm from the paper \"On the Convergence of Adam and Beyond\"\n",
    "    \n",
    "##### Todos têm learning rate!\n",
    "##### Existem ainda mais optimizers mas não sei se vale a pena ver todos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicionario = {\n",
    "    'nrCamadas':[1,2,3,4,5,6,7,8],\n",
    "    'ativacao':['relu',#'exponential',\n",
    "                'tanh','sigmoid','linear'],\n",
    "    'epochs':[10,20],\n",
    "    'batch_size':[64,128,256,512],\n",
    "    'optimizer':['rmsprop','adam','sgd'],\n",
    "    'dropout':[0.0,0.1,0.2,0.3,0.4],\n",
    "    'regularizer':[0],#1,2,3],\n",
    "    'early_stopping':[0,2,3,4,5]\n",
    "}\n",
    "neuronios = [2,3,4,5,8,10,16,32,64]\n",
    "valores_l1 = [0.1,0.01,0.001] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "numericos = ['AVProductsInstalled',\n",
    "'AVProductsEnabled',\n",
    "'Census_ProcessorCoreCount',\n",
    "'Census_PrimaryDiskTotalCapacity',\n",
    "'Census_SystemVolumeTotalCapacity',\n",
    "'Census_TotalPhysicalRAM',\n",
    "'Census_InternalPrimaryDiagonalDisplaySizeInInches',\n",
    "'Census_InternalPrimaryDisplayResolutionHorizontal',\n",
    "'Census_InternalPrimaryDisplayResolutionVertical',\n",
    "'Census_InternalBatteryNumberOfCharges']\n",
    "dtype = {}\n",
    "for df in pd.read_csv('final_sembat.csv',low_memory=False,chunksize=10):\n",
    "    for var in df.columns:\n",
    "        if var not in numericos:\n",
    "            dtype[var] = 'int8'\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "auxPred = pd.DataFrame()\n",
    "i = 0\n",
    "for tp in pd.read_csv('final_sembat.csv',low_memory=False,chunksize=50000,dtype=dtype):\n",
    "    if i == 0:\n",
    "        auxPred = pd.concat([auxPred,tp])\n",
    "    else:\n",
    "        auxPred = pd.concat([auxPred,tp],ignore_index=True)\n",
    "    i+=1\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = auxPred.loc[:499999,auxPred.columns!='HasDetections']\n",
    "valX = auxPred.loc[500000:549999,auxPred.columns!='HasDetections']\n",
    "trainY = auxPred.loc[:499999,'HasDetections']\n",
    "valY = auxPred.loc[500000:549999,'HasDetections']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del auxPred\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 707)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 707)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import math\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "def realizaVarThreshold():\n",
    "    indices = []\n",
    "    col = trainX.columns\n",
    "    total = len(col)\n",
    "    chunk = math.floor(total / 10)\n",
    "    print(chunk)\n",
    "    quantos = 0\n",
    "    for i in range(chunk):\n",
    "        sel = VarianceThreshold(threshold=0.001)\n",
    "        try:\n",
    "            sel.fit(trainX[col[quantos:quantos+10]])\n",
    "            aux = [i+quantos for i in sel.get_support(indices=True)]\n",
    "            indices.extend(aux)\n",
    "        except:\n",
    "            pass\n",
    "        del sel\n",
    "        gc.collect()\n",
    "        quantos = quantos+10\n",
    "    sel = VarianceThreshold(threshold=0.001)\n",
    "    try:\n",
    "        sel.fit(trainX[col[quantos:quantos+7]])\n",
    "        indices.extend(sel.get_support(indices=True))\n",
    "    except:\n",
    "        pass\n",
    "    del sel\n",
    "    gc.collect()\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "indices = realizaVarThreshold()\n",
    "print(len(indices))\n",
    "col = []\n",
    "coln = trainX.columns\n",
    "for i in indices:\n",
    "       col.append(coln[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'regularizer': 0, 'optimizer': 'rmsprop', 'nrCamadas': 4, 'epochs': 10, 'early_stopping': 4, 'dropout': 0.3, 'batch_size': 256, 'ativacao': 'linear', 'topologia': [10, 5, 10, 3]}\n",
      "WARNING:tensorflow:From /home/jose/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/jose/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/jose/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 500000 samples, validate on 50000 samples\n",
      "Epoch 1/10\n",
      "500000/500000 [==============================] - 11s 23us/step - loss: 7.7850 - acc: 0.5001 - val_loss: 7.9766 - val_acc: 0.4997\n",
      "Epoch 2/10\n",
      "500000/500000 [==============================] - 11s 22us/step - loss: 7.8054 - acc: 0.4988 - val_loss: 8.1333 - val_acc: 0.4915\n",
      "Epoch 3/10\n",
      "500000/500000 [==============================] - 11s 22us/step - loss: 7.7639 - acc: 0.4989 - val_loss: 8.0536 - val_acc: 0.5003\n",
      "Epoch 4/10\n",
      "500000/500000 [==============================] - 11s 22us/step - loss: 7.5366 - acc: 0.5007 - val_loss: 8.1284 - val_acc: 0.4917\n",
      "Epoch 5/10\n",
      "500000/500000 [==============================] - 11s 22us/step - loss: 7.4975 - acc: 0.4993 - val_loss: 8.0536 - val_acc: 0.5003\n",
      "Epoch 00005: early stopping\n",
      "{'regularizer': 0, 'optimizer': 'rmsprop', 'nrCamadas': 8, 'epochs': 20, 'early_stopping': 2, 'dropout': 0.0, 'batch_size': 256, 'ativacao': 'tanh', 'topologia': [32, 32, 10, 3, 8, 4, 4, 64]}\n",
      "Train on 500000 samples, validate on 50000 samples\n",
      "Epoch 1/20\n",
      "500000/500000 [==============================] - 12s 23us/step - loss: 0.6920 - acc: 0.5228 - val_loss: 0.6925 - val_acc: 0.5245\n",
      "Epoch 2/20\n",
      "500000/500000 [==============================] - 11s 23us/step - loss: 0.6919 - acc: 0.5251 - val_loss: 0.6917 - val_acc: 0.5254\n",
      "Epoch 3/20\n",
      "500000/500000 [==============================] - 11s 23us/step - loss: 0.6919 - acc: 0.5252 - val_loss: 0.6917 - val_acc: 0.5254\n",
      "Epoch 4/20\n",
      "500000/500000 [==============================] - 11s 23us/step - loss: 0.6918 - acc: 0.5253 - val_loss: 0.6921 - val_acc: 0.5252\n",
      "Epoch 00004: early stopping\n",
      "{'regularizer': 0, 'optimizer': 'adam', 'nrCamadas': 6, 'epochs': 10, 'early_stopping': 5, 'dropout': 0.3, 'batch_size': 256, 'ativacao': 'linear', 'topologia': [64, 2, 32, 10, 5, 4]}\n",
      "Train on 500000 samples, validate on 50000 samples\n",
      "Epoch 1/10\n",
      "500000/500000 [==============================] - 13s 25us/step - loss: 7.2594 - acc: 0.5020 - val_loss: 7.8899 - val_acc: 0.5090\n",
      "Epoch 2/10\n",
      "500000/500000 [==============================] - 12s 25us/step - loss: 7.2804 - acc: 0.5017 - val_loss: 8.0536 - val_acc: 0.5003\n",
      "Epoch 3/10\n",
      "500000/500000 [==============================] - 12s 24us/step - loss: 7.2543 - acc: 0.5022 - val_loss: 7.8988 - val_acc: 0.5084\n",
      "Epoch 4/10\n",
      "500000/500000 [==============================] - 13s 25us/step - loss: 7.2472 - acc: 0.5019 - val_loss: 7.8899 - val_acc: 0.5090\n",
      "Epoch 5/10\n",
      "500000/500000 [==============================] - 13s 25us/step - loss: 7.2903 - acc: 0.4998 - val_loss: 8.1402 - val_acc: 0.4910\n",
      "Epoch 6/10\n",
      "500000/500000 [==============================] - 12s 25us/step - loss: 7.3149 - acc: 0.4983 - val_loss: 8.1402 - val_acc: 0.4910\n",
      "Epoch 00006: early stopping\n",
      "{'regularizer': 0, 'optimizer': 'adam', 'nrCamadas': 7, 'epochs': 20, 'early_stopping': 2, 'dropout': 0.0, 'batch_size': 256, 'ativacao': 'tanh', 'topologia': [16, 8, 16, 10, 3, 16, 64]}\n",
      "Train on 500000 samples, validate on 50000 samples\n",
      "Epoch 1/20\n",
      "500000/500000 [==============================] - 12s 24us/step - loss: 0.6922 - acc: 0.5231 - val_loss: 0.6931 - val_acc: 0.5018\n",
      "Epoch 2/20\n",
      "500000/500000 [==============================] - 12s 23us/step - loss: 0.6927 - acc: 0.5132 - val_loss: 0.6937 - val_acc: 0.5121\n",
      "Epoch 3/20\n",
      "500000/500000 [==============================] - 12s 23us/step - loss: 0.6928 - acc: 0.5117 - val_loss: 0.6923 - val_acc: 0.5200\n",
      "Epoch 4/20\n",
      "500000/500000 [==============================] - 12s 24us/step - loss: 0.6928 - acc: 0.5121 - val_loss: 0.6925 - val_acc: 0.5169\n",
      "Epoch 5/20\n",
      "500000/500000 [==============================] - 12s 23us/step - loss: 0.6920 - acc: 0.5236 - val_loss: 0.6919 - val_acc: 0.5254\n",
      "Epoch 6/20\n",
      "500000/500000 [==============================] - 12s 23us/step - loss: 0.6919 - acc: 0.5253 - val_loss: 0.6919 - val_acc: 0.5254\n",
      "Epoch 7/20\n",
      "500000/500000 [==============================] - 12s 23us/step - loss: 0.6919 - acc: 0.5245 - val_loss: 0.6917 - val_acc: 0.5254\n",
      "Epoch 8/20\n",
      "500000/500000 [==============================] - 12s 23us/step - loss: 0.6920 - acc: 0.5225 - val_loss: 0.6923 - val_acc: 0.5183\n",
      "Epoch 9/20\n",
      "500000/500000 [==============================] - 12s 23us/step - loss: 0.6925 - acc: 0.5157 - val_loss: 0.6930 - val_acc: 0.5091\n",
      "Epoch 00009: early stopping\n",
      "{'regularizer': 0, 'optimizer': 'rmsprop', 'nrCamadas': 5, 'epochs': 10, 'early_stopping': 0, 'dropout': 0.4, 'batch_size': 512, 'ativacao': 'tanh', 'topologia': [64, 10, 2, 2, 3]}\n",
      "Train on 500000 samples, validate on 50000 samples\n",
      "Epoch 1/10\n",
      "500000/500000 [==============================] - 11s 22us/step - loss: 0.6965 - acc: 0.5000 - val_loss: 0.6930 - val_acc: 0.5089\n",
      "Epoch 2/10\n",
      "500000/500000 [==============================] - 10s 21us/step - loss: 0.6930 - acc: 0.5066 - val_loss: 0.6923 - val_acc: 0.5234\n",
      "Epoch 3/10\n",
      "500000/500000 [==============================] - 10s 21us/step - loss: 0.6928 - acc: 0.5124 - val_loss: 0.6923 - val_acc: 0.5241\n",
      "Epoch 4/10\n",
      "500000/500000 [==============================] - 10s 21us/step - loss: 0.6927 - acc: 0.5146 - val_loss: 0.6922 - val_acc: 0.5237\n",
      "Epoch 5/10\n",
      "500000/500000 [==============================] - 10s 21us/step - loss: 0.6926 - acc: 0.5145 - val_loss: 0.6922 - val_acc: 0.5255\n",
      "Epoch 6/10\n",
      "500000/500000 [==============================] - 10s 21us/step - loss: 0.6926 - acc: 0.5160 - val_loss: 0.6921 - val_acc: 0.5252\n",
      "Epoch 7/10\n",
      "500000/500000 [==============================] - 10s 21us/step - loss: 0.6926 - acc: 0.5153 - val_loss: 0.6923 - val_acc: 0.5253\n",
      "Epoch 8/10\n",
      "500000/500000 [==============================] - 10s 21us/step - loss: 0.6926 - acc: 0.5152 - val_loss: 0.6924 - val_acc: 0.5253\n",
      "Epoch 9/10\n",
      "500000/500000 [==============================] - 10s 21us/step - loss: 0.6926 - acc: 0.5163 - val_loss: 0.6922 - val_acc: 0.5251\n",
      "Epoch 10/10\n",
      "500000/500000 [==============================] - 10s 21us/step - loss: 0.6926 - acc: 0.5158 - val_loss: 0.6923 - val_acc: 0.5255\n",
      "{'regularizer': 0, 'optimizer': 'adam', 'nrCamadas': 1, 'epochs': 20, 'early_stopping': 3, 'dropout': 0.2, 'batch_size': 64, 'ativacao': 'sigmoid', 'topologia': [64]}\n",
      "Train on 500000 samples, validate on 50000 samples\n",
      "Epoch 1/20\n",
      "500000/500000 [==============================] - 17s 34us/step - loss: 0.6962 - acc: 0.5096 - val_loss: 0.6934 - val_acc: 0.5020\n",
      "Epoch 2/20\n",
      "500000/500000 [==============================] - 16s 33us/step - loss: 0.6933 - acc: 0.5082 - val_loss: 0.6931 - val_acc: 0.5089\n",
      "Epoch 3/20\n",
      "500000/500000 [==============================] - 16s 33us/step - loss: 0.6935 - acc: 0.5044 - val_loss: 0.6932 - val_acc: 0.4997\n",
      "Epoch 4/20\n",
      "500000/500000 [==============================] - 16s 33us/step - loss: 0.6935 - acc: 0.5054 - val_loss: 0.6931 - val_acc: 0.4998\n",
      "Epoch 5/20\n",
      "500000/500000 [==============================] - 16s 33us/step - loss: 0.6935 - acc: 0.5057 - val_loss: 0.6952 - val_acc: 0.5003\n",
      "Epoch 00005: early stopping\n",
      "{'regularizer': 0, 'optimizer': 'sgd', 'nrCamadas': 2, 'epochs': 20, 'early_stopping': 0, 'dropout': 0.0, 'batch_size': 64, 'ativacao': 'tanh', 'topologia': [4, 5]}\n",
      "Train on 500000 samples, validate on 50000 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000/500000 [==============================] - 13s 27us/step - loss: 0.6941 - acc: 0.5093 - val_loss: 0.6931 - val_acc: 0.5090\n",
      "Epoch 2/20\n",
      "500000/500000 [==============================] - 13s 26us/step - loss: 0.6929 - acc: 0.5099 - val_loss: 0.6931 - val_acc: 0.5090\n",
      "Epoch 3/20\n",
      "500000/500000 [==============================] - 13s 26us/step - loss: 0.6929 - acc: 0.5099 - val_loss: 0.6931 - val_acc: 0.5090\n",
      "Epoch 4/20\n",
      "500000/500000 [==============================] - 13s 26us/step - loss: 0.6929 - acc: 0.5089 - val_loss: 0.6930 - val_acc: 0.5090\n",
      "Epoch 5/20\n",
      "500000/500000 [==============================] - 13s 26us/step - loss: 0.6929 - acc: 0.5096 - val_loss: 0.6931 - val_acc: 0.5090\n",
      "Epoch 6/20\n",
      "500000/500000 [==============================] - 13s 26us/step - loss: 0.6929 - acc: 0.5094 - val_loss: 0.6930 - val_acc: 0.5090\n",
      "Epoch 7/20\n",
      "500000/500000 [==============================] - 13s 26us/step - loss: 0.6929 - acc: 0.5099 - val_loss: 0.6930 - val_acc: 0.5090\n",
      "Epoch 8/20\n",
      "500000/500000 [==============================] - 13s 26us/step - loss: 0.6929 - acc: 0.5097 - val_loss: 0.6930 - val_acc: 0.5090\n",
      "Epoch 9/20\n",
      "500000/500000 [==============================] - 13s 26us/step - loss: 0.6929 - acc: 0.5095 - val_loss: 0.6930 - val_acc: 0.5090\n",
      "Epoch 10/20\n",
      "500000/500000 [==============================] - 13s 26us/step - loss: 0.6929 - acc: 0.5099 - val_loss: 0.6930 - val_acc: 0.5090\n",
      "Epoch 11/20\n",
      "500000/500000 [==============================] - 13s 26us/step - loss: 0.6929 - acc: 0.5100 - val_loss: 0.6930 - val_acc: 0.5090\n",
      "Epoch 12/20\n",
      "500000/500000 [==============================] - 13s 26us/step - loss: 0.6929 - acc: 0.5096 - val_loss: 0.6930 - val_acc: 0.5090\n",
      "Epoch 13/20\n",
      "500000/500000 [==============================] - 13s 26us/step - loss: 0.6929 - acc: 0.5099 - val_loss: 0.6930 - val_acc: 0.5090\n",
      "Epoch 14/20\n",
      "500000/500000 [==============================] - 13s 26us/step - loss: 0.6929 - acc: 0.5099 - val_loss: 0.6930 - val_acc: 0.5090\n",
      "Epoch 15/20\n",
      "500000/500000 [==============================] - 13s 26us/step - loss: 0.6929 - acc: 0.5094 - val_loss: 0.6930 - val_acc: 0.5090\n",
      "Epoch 16/20\n",
      "500000/500000 [==============================] - 13s 26us/step - loss: 0.6929 - acc: 0.5094 - val_loss: 0.6931 - val_acc: 0.5090\n",
      "Epoch 17/20\n",
      "500000/500000 [==============================] - 13s 26us/step - loss: 0.6929 - acc: 0.5095 - val_loss: 0.6930 - val_acc: 0.5090\n",
      "Epoch 18/20\n",
      "500000/500000 [==============================] - 13s 26us/step - loss: 0.6929 - acc: 0.5097 - val_loss: 0.6930 - val_acc: 0.5090\n",
      "Epoch 19/20\n",
      "500000/500000 [==============================] - 13s 26us/step - loss: 0.6929 - acc: 0.5091 - val_loss: 0.6931 - val_acc: 0.5090\n",
      "Epoch 20/20\n",
      "500000/500000 [==============================] - 13s 25us/step - loss: 0.6929 - acc: 0.5096 - val_loss: 0.6930 - val_acc: 0.5090\n",
      "{'regularizer': 0, 'optimizer': 'rmsprop', 'nrCamadas': 1, 'epochs': 10, 'early_stopping': 4, 'dropout': 0.4, 'batch_size': 256, 'ativacao': 'linear', 'topologia': [64]}\n",
      "Train on 500000 samples, validate on 50000 samples\n",
      "Epoch 1/10\n",
      "500000/500000 [==============================] - 12s 25us/step - loss: 7.9801 - acc: 0.4998 - val_loss: 7.9766 - val_acc: 0.4997\n",
      "Epoch 2/10\n",
      "500000/500000 [==============================] - 12s 23us/step - loss: 7.9521 - acc: 0.5029 - val_loss: 7.6915 - val_acc: 0.5208\n",
      "Epoch 3/10\n",
      "500000/500000 [==============================] - 12s 24us/step - loss: 7.9182 - acc: 0.5051 - val_loss: 7.9766 - val_acc: 0.4997\n",
      "Epoch 4/10\n",
      "500000/500000 [==============================] - 12s 24us/step - loss: 7.9781 - acc: 0.5007 - val_loss: 7.9766 - val_acc: 0.4997\n",
      "Epoch 5/10\n",
      "500000/500000 [==============================] - 12s 24us/step - loss: 8.0059 - acc: 0.4990 - val_loss: 7.9766 - val_acc: 0.4997\n",
      "Epoch 6/10\n",
      "500000/500000 [==============================] - 12s 23us/step - loss: 8.0288 - acc: 0.4969 - val_loss: 7.9766 - val_acc: 0.4997\n",
      "Epoch 00006: early stopping\n",
      "{'regularizer': 0, 'optimizer': 'adam', 'nrCamadas': 5, 'epochs': 10, 'early_stopping': 2, 'dropout': 0.2, 'batch_size': 64, 'ativacao': 'sigmoid', 'topologia': [4, 8, 5, 2, 10]}\n",
      "Train on 500000 samples, validate on 50000 samples\n",
      "Epoch 1/10\n",
      "500000/500000 [==============================] - 18s 36us/step - loss: 0.6955 - acc: 0.5008 - val_loss: 0.6932 - val_acc: 0.5003\n",
      "Epoch 2/10\n",
      "500000/500000 [==============================] - 17s 34us/step - loss: 0.6932 - acc: 0.4997 - val_loss: 0.6933 - val_acc: 0.5003\n",
      "Epoch 3/10\n",
      "500000/500000 [==============================] - 17s 34us/step - loss: 0.6932 - acc: 0.4994 - val_loss: 0.6933 - val_acc: 0.4997\n",
      "Epoch 00003: early stopping\n",
      "{'regularizer': 0, 'optimizer': 'sgd', 'nrCamadas': 6, 'epochs': 10, 'early_stopping': 4, 'dropout': 0.2, 'batch_size': 128, 'ativacao': 'linear', 'topologia': [32, 3, 4, 5, 2, 8]}\n",
      "Train on 500000 samples, validate on 50000 samples\n",
      "Epoch 1/10\n",
      "500000/500000 [==============================] - 15s 30us/step - loss: 7.6842 - acc: 0.4992 - val_loss: 7.8899 - val_acc: 0.5090\n",
      "Epoch 2/10\n",
      "500000/500000 [==============================] - 14s 29us/step - loss: 7.6560 - acc: 0.5041 - val_loss: 7.8899 - val_acc: 0.5090\n",
      "Epoch 3/10\n",
      "500000/500000 [==============================] - 14s 29us/step - loss: 7.6591 - acc: 0.5042 - val_loss: 7.8899 - val_acc: 0.5090\n",
      "Epoch 4/10\n",
      "500000/500000 [==============================] - 14s 29us/step - loss: 7.6673 - acc: 0.5036 - val_loss: 7.8899 - val_acc: 0.5090\n",
      "Epoch 5/10\n",
      "500000/500000 [==============================] - 14s 28us/step - loss: 7.6804 - acc: 0.5028 - val_loss: 7.8899 - val_acc: 0.5090\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "res = optimizacaoHyperParametros(dicionario,neuronios,valores_l1,\n",
    "                          trainX[col],trainY,\n",
    "                          valX[col],valY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ativacao</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>early_stopping</th>\n",
       "      <th>epochs</th>\n",
       "      <th>nrCamadas</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>regularizer</th>\n",
       "      <th>score</th>\n",
       "      <th>topologia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tanh</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0</td>\n",
       "      <td>0.529797</td>\n",
       "      <td>[32, 32, 10, 3, 8, 4, 4, 64]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tanh</td>\n",
       "      <td>512</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0</td>\n",
       "      <td>0.528062</td>\n",
       "      <td>[64, 10, 2, 2, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tanh</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0</td>\n",
       "      <td>0.508834</td>\n",
       "      <td>[4, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>linear</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0</td>\n",
       "      <td>0.508834</td>\n",
       "      <td>[32, 3, 4, 5, 2, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tanh</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>adam</td>\n",
       "      <td>0</td>\n",
       "      <td>0.508826</td>\n",
       "      <td>[16, 8, 16, 10, 3, 16, 64]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>adam</td>\n",
       "      <td>0</td>\n",
       "      <td>0.508737</td>\n",
       "      <td>[64]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[10, 5, 10, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>linear</td>\n",
       "      <td>256</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[64]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>adam</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[4, 8, 5, 2, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>linear</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>adam</td>\n",
       "      <td>0</td>\n",
       "      <td>0.491166</td>\n",
       "      <td>[64, 2, 32, 10, 5, 4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ativacao  batch_size  dropout  early_stopping  epochs  nrCamadas optimizer  \\\n",
       "1     tanh         256      0.0               2      20          8   rmsprop   \n",
       "4     tanh         512      0.4               0      10          5   rmsprop   \n",
       "6     tanh          64      0.0               0      20          2       sgd   \n",
       "9   linear         128      0.2               4      10          6       sgd   \n",
       "3     tanh         256      0.0               2      20          7      adam   \n",
       "5  sigmoid          64      0.2               3      20          1      adam   \n",
       "0   linear         256      0.3               4      10          4   rmsprop   \n",
       "7   linear         256      0.4               4      10          1   rmsprop   \n",
       "8  sigmoid          64      0.2               2      10          5      adam   \n",
       "2   linear         256      0.3               5      10          6      adam   \n",
       "\n",
       "   regularizer     score                     topologia  \n",
       "1            0  0.529797  [32, 32, 10, 3, 8, 4, 4, 64]  \n",
       "4            0  0.528062             [64, 10, 2, 2, 3]  \n",
       "6            0  0.508834                        [4, 5]  \n",
       "9            0  0.508834           [32, 3, 4, 5, 2, 8]  \n",
       "3            0  0.508826    [16, 8, 16, 10, 3, 16, 64]  \n",
       "5            0  0.508737                          [64]  \n",
       "0            0  0.500000                [10, 5, 10, 3]  \n",
       "7            0  0.500000                          [64]  \n",
       "8            0  0.500000              [4, 8, 5, 2, 10]  \n",
       "2            0  0.491166         [64, 2, 32, 10, 5, 4]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado = pd.DataFrame(res)\n",
    "resultado.sort_values(by=['score'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "427.900328"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(trainY.memory_usage() + valY.memory_usage() + \n",
    " trainX.memory_usage().sum() + valX.memory_usage().sum()) / (1000*1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
