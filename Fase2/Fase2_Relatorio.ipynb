{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimização de hyper-parâmetros\n",
    "\n",
    "A ideia é que esta função selecione um número X de diferentes redes.\n",
    "\n",
    "Depois vamos criar uma função que para cada rede, vai fazer o treino e testar o score com os dados de validação. Essa função depois ordena consoante o melhor valor de AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterSampler\n",
    "import random as r\n",
    "def selecaoHyperParametros(d,neuronios,reg):\n",
    "    lista_parametros = list(ParameterSampler(d, n_iter=4, random_state=10))\n",
    "    r.seed(10)\n",
    "    for var in lista_parametros:\n",
    "        var['topologia'] = r.choices(neuronios,k=var['nrCamadas'])\n",
    "        aux = var['regularizer']\n",
    "        if aux == 1:\n",
    "            var['l1'] = r.choice(reg)\n",
    "        elif aux == 2:\n",
    "            var['l2'] = r.choice(reg)\n",
    "        elif aux == 3:\n",
    "            var['l1'] = r.choice(reg)\n",
    "            var['l2'] = r.choice(reg)\n",
    "        else:\n",
    "            pass\n",
    "    return lista_parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models,layers,regularizers\n",
    "def criaRede(param,inputSize):\n",
    "    model=models.Sequential()\n",
    "    aux = param['regularizer']\n",
    "    kernel_reg = None\n",
    "    '''if aux == 1:\n",
    "        kernel_reg = regularizers.l1(param['l1'])\n",
    "    elif aux == 2:\n",
    "        kernel_reg = regularizers.l2(param['l2'])\n",
    "    elif aux == 3:\n",
    "        kernel_reg = regularizers.l1_l2(l1=param['l1'],l2=param['l2'])\n",
    "    else:\n",
    "        pass '''\n",
    "    \n",
    "    model.add(layers.Dense(param['topologia'][0],activation=param['ativacao'],\n",
    "                           kernel_regularizer=kernel_reg,input_shape=(inputSize,)))\n",
    "    if param['dropout'] > 0:\n",
    "        model.add(layers.Dropout(param['dropout']))\n",
    "    for var in param['topologia'][1:]:\n",
    "        model.add(layers.Dense(var,activation=param['ativacao'],kernel_regularizer=kernel_reg))\n",
    "        if param['dropout'] > 0:\n",
    "            model.add(layers.Dropout(param['dropout']))\n",
    "    model.add(layers.Dense(1,activation='sigmoid'))\n",
    "    model.compile(optimizer=param['optimizer'],\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from keras.callbacks import EarlyStopping\n",
    "def optimizacaoHyperParametros(d,neuronios,reg,trainX,trainY,valX,valY):\n",
    "    params = selecaoHyperParametros(d,neuronios,reg)\n",
    "    for param in params:\n",
    "        print(param)\n",
    "        rede = criaRede(param,trainX.shape[1])\n",
    "        if param['early_stopping'] > 0:\n",
    "            early = EarlyStopping(monitor='val_loss',patience=param['early_stopping'])\n",
    "            history = rede.fit(trainX,\n",
    "                                trainY,\n",
    "                                epochs=param['epochs'],\n",
    "                                batch_size=param['batch_size'],\n",
    "                                validation_data=(valX,valY),\n",
    "                                  callbacks=[early])\n",
    "        else:\n",
    "            history = rede.fit(trainX,\n",
    "                                trainY,\n",
    "                                epochs=param['epochs'],\n",
    "                                batch_size=param['batch_size'],\n",
    "                                validation_data=(valX,valY))\n",
    "        pred = rede.predict(valX)\n",
    "        false_positive_rate, true_positive_rate, thresholds = roc_curve(valY, pred)\n",
    "        score = auc(false_positive_rate, true_positive_rate)\n",
    "        param['score'] = score\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aqui estão os parametros que vamos optimizar\n",
    "\n",
    "### Faltam ainda ver o dropout, early stopping e regularização\n",
    "\n",
    "### Optimizer temos de ver os parâmetros existentes também:\n",
    "- rmsprop\n",
    "    - rho: float >= 0.\n",
    "    - epsilon: float >= 0. Fuzz factor. If None, defaults to K.epsilon().\n",
    "    - decay: float >= 0. Learning rate decay over each update.\n",
    "- SGD\n",
    "    - momentum: float >= 0. Parameter that accelerates SGD in the relevant direction and dampens oscillations.\n",
    "    - decay: float >= 0. Learning rate decay over each update.\n",
    "    - nesterov: boolean. Whether to apply Nesterov momentum.\n",
    "- Adam\n",
    "    - beta_1: float, 0 < beta < 1. Generally close to 1.\n",
    "    - beta_2: float, 0 < beta < 1. Generally close to 1.\n",
    "    - epsilon: float >= 0. Fuzz factor. If None, defaults to K.epsilon().\n",
    "    - decay: float >= 0. Learning rate decay over each update.\n",
    "    - amsgrad: boolean. Whether to apply the AMSGrad variant of this algorithm from the paper \"On the Convergence of Adam and Beyond\"\n",
    "    \n",
    "##### Todos têm learning rate!\n",
    "##### Existem ainda mais optimizers mas não sei se vale a pena ver todos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicionario = {\n",
    "    'nrCamadas':[1,2,3,4,5,6,7,8],\n",
    "    'ativacao':['relu','exponential','tanh','sigmoid','linear'],\n",
    "    'epochs':[4,8,10,20],\n",
    "    'batch_size':[64,128,256,512],\n",
    "    'optimizer':['rmsprop','adam','sgd'],\n",
    "    'dropout':[0.0,0.1,0.2,0.3,0.4],\n",
    "    'regularizer':[0],#1,2,3],\n",
    "    'early_stopping':[0],#2,3,4,5]\n",
    "}\n",
    "neuronios = [2,3,4,5,8,10,16,32,64]\n",
    "valores_l1 = [0.1,0.01,0.001] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feito\n",
      "Feito\n",
      "Feito\n",
      "Feito\n",
      "Feito\n",
      "Feito\n",
      "Feito\n",
      "Feito\n",
      "Feito\n",
      "Feito\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ms = None\n",
    "y = None\n",
    "for df in pd.read_csv('final_sembat.csv',low_memory=False,chunksize=60000):\n",
    "    if ms is None:\n",
    "        ms = df.iloc[:,0:100]\n",
    "        y = df['HasDetections']\n",
    "    else:\n",
    "        y = pd.concat([y, df['HasDetections']], ignore_index=True)\n",
    "        ms = pd.concat([ms,df.iloc[:,0:100]], ignore_index=True)\n",
    "    print('Feito')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = ms[:500000]\n",
    "valX = ms[500000:550000]\n",
    "trainY = y[:500000]\n",
    "valY = y[500000:550000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'regularizer': 0, 'optimizer': 'sgd', 'nrCamadas': 6, 'epochs': 8, 'early_stopping': 0, 'dropout': 0.3, 'batch_size': 256, 'ativacao': 'relu', 'topologia': [10, 5, 10, 3, 32, 32]}\n",
      "Train on 500000 samples, validate on 50000 samples\n",
      "Epoch 1/8\n",
      "500000/500000 [==============================] - 7s 14us/step - loss: 0.6933 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4998\n",
      "Epoch 2/8\n",
      "500000/500000 [==============================] - 6s 12us/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5016\n",
      "Epoch 3/8\n",
      "500000/500000 [==============================] - 6s 12us/step - loss: 0.6932 - acc: 0.4988 - val_loss: 0.6931 - val_acc: 0.4997\n",
      "Epoch 4/8\n",
      "500000/500000 [==============================] - 6s 12us/step - loss: 0.6932 - acc: 0.4999 - val_loss: 0.6932 - val_acc: 0.4998\n",
      "Epoch 5/8\n",
      "500000/500000 [==============================] - 6s 12us/step - loss: 0.6932 - acc: 0.4995 - val_loss: 0.6931 - val_acc: 0.5031\n",
      "Epoch 6/8\n",
      "500000/500000 [==============================] - 6s 12us/step - loss: 0.6932 - acc: 0.4993 - val_loss: 0.6932 - val_acc: 0.4998\n",
      "Epoch 7/8\n",
      "500000/500000 [==============================] - 6s 12us/step - loss: 0.6932 - acc: 0.4994 - val_loss: 0.6931 - val_acc: 0.5003\n",
      "Epoch 8/8\n",
      "500000/500000 [==============================] - 6s 12us/step - loss: 0.6932 - acc: 0.5005 - val_loss: 0.6931 - val_acc: 0.4998\n",
      "{'regularizer': 0, 'optimizer': 'rmsprop', 'nrCamadas': 8, 'epochs': 20, 'early_stopping': 0, 'dropout': 0.0, 'batch_size': 512, 'ativacao': 'sigmoid', 'topologia': [10, 3, 8, 4, 4, 64, 64, 2]}\n",
      "Train on 500000 samples, validate on 50000 samples\n",
      "Epoch 1/20\n",
      "500000/500000 [==============================] - 5s 10us/step - loss: 0.6939 - acc: 0.5008 - val_loss: 0.6932 - val_acc: 0.4997\n",
      "Epoch 2/20\n",
      "500000/500000 [==============================] - 4s 8us/step - loss: 0.6932 - acc: 0.5003 - val_loss: 0.6932 - val_acc: 0.4997\n",
      "Epoch 3/20\n",
      "500000/500000 [==============================] - 4s 8us/step - loss: 0.6932 - acc: 0.5005 - val_loss: 0.6932 - val_acc: 0.5003\n",
      "Epoch 4/20\n",
      "500000/500000 [==============================] - 4s 8us/step - loss: 0.6932 - acc: 0.4991 - val_loss: 0.6932 - val_acc: 0.5003\n",
      "Epoch 5/20\n",
      "500000/500000 [==============================] - 4s 8us/step - loss: 0.6932 - acc: 0.5021 - val_loss: 0.6932 - val_acc: 0.4997\n",
      "Epoch 6/20\n",
      "500000/500000 [==============================] - 4s 8us/step - loss: 0.6931 - acc: 0.5020 - val_loss: 0.6932 - val_acc: 0.5003\n",
      "Epoch 7/20\n",
      "500000/500000 [==============================] - 4s 8us/step - loss: 0.6932 - acc: 0.5005 - val_loss: 0.6932 - val_acc: 0.4997\n",
      "Epoch 8/20\n",
      "500000/500000 [==============================] - 4s 8us/step - loss: 0.6932 - acc: 0.5019 - val_loss: 0.6932 - val_acc: 0.4997\n",
      "Epoch 9/20\n",
      "500000/500000 [==============================] - 5s 9us/step - loss: 0.6932 - acc: 0.4994 - val_loss: 0.6932 - val_acc: 0.4997\n",
      "Epoch 10/20\n",
      "500000/500000 [==============================] - 4s 8us/step - loss: 0.6932 - acc: 0.5005 - val_loss: 0.6931 - val_acc: 0.5003\n",
      "Epoch 11/20\n",
      "500000/500000 [==============================] - 4s 8us/step - loss: 0.6932 - acc: 0.4993 - val_loss: 0.6932 - val_acc: 0.4997\n",
      "Epoch 12/20\n",
      "500000/500000 [==============================] - 4s 8us/step - loss: 0.6932 - acc: 0.4998 - val_loss: 0.6931 - val_acc: 0.5003\n",
      "Epoch 13/20\n",
      "500000/500000 [==============================] - 4s 8us/step - loss: 0.6932 - acc: 0.4990 - val_loss: 0.6932 - val_acc: 0.4997\n",
      "Epoch 14/20\n",
      "500000/500000 [==============================] - 4s 8us/step - loss: 0.6932 - acc: 0.4994 - val_loss: 0.6932 - val_acc: 0.4997\n",
      "Epoch 15/20\n",
      "500000/500000 [==============================] - 4s 8us/step - loss: 0.6930 - acc: 0.5042 - val_loss: 0.6919 - val_acc: 0.5286\n",
      "Epoch 16/20\n",
      "500000/500000 [==============================] - 4s 8us/step - loss: 0.6901 - acc: 0.5297 - val_loss: 0.6891 - val_acc: 0.5309\n",
      "Epoch 17/20\n",
      "500000/500000 [==============================] - 4s 8us/step - loss: 0.6893 - acc: 0.5333 - val_loss: 0.6890 - val_acc: 0.5336\n",
      "Epoch 18/20\n",
      "500000/500000 [==============================] - 4s 8us/step - loss: 0.6891 - acc: 0.5341 - val_loss: 0.6888 - val_acc: 0.5353\n",
      "Epoch 19/20\n",
      "500000/500000 [==============================] - 4s 8us/step - loss: 0.6890 - acc: 0.5341 - val_loss: 0.6897 - val_acc: 0.5300\n",
      "Epoch 20/20\n",
      "500000/500000 [==============================] - 4s 8us/step - loss: 0.6889 - acc: 0.5341 - val_loss: 0.6888 - val_acc: 0.5352\n",
      "{'regularizer': 0, 'optimizer': 'rmsprop', 'nrCamadas': 1, 'epochs': 4, 'early_stopping': 0, 'dropout': 0.4, 'batch_size': 256, 'ativacao': 'relu', 'topologia': [32]}\n",
      "Train on 500000 samples, validate on 50000 samples\n",
      "Epoch 1/4\n",
      "500000/500000 [==============================] - 5s 10us/step - loss: 0.6906 - acc: 0.5251 - val_loss: 0.6884 - val_acc: 0.5349\n",
      "Epoch 2/4\n",
      "500000/500000 [==============================] - 4s 8us/step - loss: 0.6889 - acc: 0.5327 - val_loss: 0.6882 - val_acc: 0.5355\n",
      "Epoch 3/4\n",
      "500000/500000 [==============================] - 4s 8us/step - loss: 0.6886 - acc: 0.5342 - val_loss: 0.6882 - val_acc: 0.5331\n",
      "Epoch 4/4\n",
      "500000/500000 [==============================] - 4s 8us/step - loss: 0.6885 - acc: 0.5347 - val_loss: 0.6879 - val_acc: 0.5350\n",
      "{'regularizer': 0, 'optimizer': 'adam', 'nrCamadas': 7, 'epochs': 20, 'early_stopping': 0, 'dropout': 0.0, 'batch_size': 512, 'ativacao': 'sigmoid', 'topologia': [10, 5, 4, 16, 8, 16, 10]}\n",
      "Train on 500000 samples, validate on 50000 samples\n",
      "Epoch 1/20\n",
      "500000/500000 [==============================] - 5s 9us/step - loss: 0.6936 - acc: 0.5008 - val_loss: 0.6932 - val_acc: 0.4997\n",
      "Epoch 2/20\n",
      "500000/500000 [==============================] - 3s 6us/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.4997\n",
      "Epoch 3/20\n",
      "500000/500000 [==============================] - 3s 7us/step - loss: 0.6917 - acc: 0.5201 - val_loss: 0.6893 - val_acc: 0.5341\n",
      "Epoch 4/20\n",
      "500000/500000 [==============================] - 4s 8us/step - loss: 0.6893 - acc: 0.5341 - val_loss: 0.6890 - val_acc: 0.5348\n",
      "Epoch 5/20\n",
      "500000/500000 [==============================] - 4s 7us/step - loss: 0.6890 - acc: 0.5344 - val_loss: 0.6889 - val_acc: 0.5344\n",
      "Epoch 6/20\n",
      "500000/500000 [==============================] - 4s 7us/step - loss: 0.6889 - acc: 0.5345 - val_loss: 0.6887 - val_acc: 0.5348\n",
      "Epoch 7/20\n",
      "500000/500000 [==============================] - 4s 7us/step - loss: 0.6888 - acc: 0.5345 - val_loss: 0.6887 - val_acc: 0.5355\n",
      "Epoch 8/20\n",
      "500000/500000 [==============================] - 4s 7us/step - loss: 0.6887 - acc: 0.5344 - val_loss: 0.6887 - val_acc: 0.5350\n",
      "Epoch 9/20\n",
      "500000/500000 [==============================] - 4s 7us/step - loss: 0.6888 - acc: 0.5347 - val_loss: 0.6886 - val_acc: 0.5351\n",
      "Epoch 10/20\n",
      "500000/500000 [==============================] - 4s 7us/step - loss: 0.6887 - acc: 0.5345 - val_loss: 0.6886 - val_acc: 0.5350\n",
      "Epoch 11/20\n",
      "500000/500000 [==============================] - 4s 7us/step - loss: 0.6887 - acc: 0.5351 - val_loss: 0.6886 - val_acc: 0.5348\n",
      "Epoch 12/20\n",
      "500000/500000 [==============================] - 4s 7us/step - loss: 0.6887 - acc: 0.5344 - val_loss: 0.6886 - val_acc: 0.5351\n",
      "Epoch 13/20\n",
      "500000/500000 [==============================] - 4s 7us/step - loss: 0.6886 - acc: 0.5345 - val_loss: 0.6889 - val_acc: 0.5310\n",
      "Epoch 14/20\n",
      "500000/500000 [==============================] - 4s 7us/step - loss: 0.6886 - acc: 0.5349 - val_loss: 0.6885 - val_acc: 0.5350\n",
      "Epoch 15/20\n",
      "500000/500000 [==============================] - 4s 7us/step - loss: 0.6886 - acc: 0.5344 - val_loss: 0.6886 - val_acc: 0.5359\n",
      "Epoch 16/20\n",
      "500000/500000 [==============================] - 4s 7us/step - loss: 0.6886 - acc: 0.5347 - val_loss: 0.6885 - val_acc: 0.5349\n",
      "Epoch 17/20\n",
      "500000/500000 [==============================] - 4s 7us/step - loss: 0.6886 - acc: 0.5344 - val_loss: 0.6885 - val_acc: 0.5348\n",
      "Epoch 18/20\n",
      "500000/500000 [==============================] - 4s 7us/step - loss: 0.6886 - acc: 0.5345 - val_loss: 0.6885 - val_acc: 0.5357\n",
      "Epoch 19/20\n",
      "500000/500000 [==============================] - 4s 7us/step - loss: 0.6886 - acc: 0.5343 - val_loss: 0.6885 - val_acc: 0.5352\n",
      "Epoch 20/20\n",
      "500000/500000 [==============================] - 4s 7us/step - loss: 0.6886 - acc: 0.5344 - val_loss: 0.6884 - val_acc: 0.5352\n"
     ]
    }
   ],
   "source": [
    "res = optimizacaoHyperParametros(dicionario,neuronios,valores_l1,\n",
    "                          trainX,trainY,\n",
    "                          valX,valY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ativacao</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>early_stopping</th>\n",
       "      <th>epochs</th>\n",
       "      <th>nrCamadas</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>regularizer</th>\n",
       "      <th>score</th>\n",
       "      <th>topologia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0</td>\n",
       "      <td>0.550640</td>\n",
       "      <td>[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>adam</td>\n",
       "      <td>0</td>\n",
       "      <td>0.548682</td>\n",
       "      <td>[10, 5, 4, 16, 8, 16, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0</td>\n",
       "      <td>0.547942</td>\n",
       "      <td>[10, 3, 8, 4, 4, 64, 64, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0</td>\n",
       "      <td>0.502012</td>\n",
       "      <td>[10, 5, 10, 3, 32, 32]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ativacao  batch_size  dropout  early_stopping  epochs  nrCamadas optimizer  \\\n",
       "2     relu         256      0.4               0       4          1   rmsprop   \n",
       "3  sigmoid         512      0.0               0      20          7      adam   \n",
       "1  sigmoid         512      0.0               0      20          8   rmsprop   \n",
       "0     relu         256      0.3               0       8          6       sgd   \n",
       "\n",
       "   regularizer     score                    topologia  \n",
       "2            0  0.550640                         [32]  \n",
       "3            0  0.548682    [10, 5, 4, 16, 8, 16, 10]  \n",
       "1            0  0.547942  [10, 3, 8, 4, 4, 64, 64, 2]  \n",
       "0            0  0.502012       [10, 5, 10, 3, 32, 32]  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado = pd.DataFrame(res)\n",
    "resultado.sort_values(by=['score'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'optimizer': 'sgd', 'nrCamadas': 6, 'epochs': 8, 'batch_size': 128, 'ativacao': 'sigmoid', 'topologia': [10, 5, 10, 3, 32, 32]}\n",
      "\n",
      "{'optimizer': 'rmsprop', 'nrCamadas': 8, 'epochs': 20, 'batch_size': 512, 'ativacao': 'tanh', 'topologia': [10, 3, 8, 4, 4, 64, 64, 2]}\n",
      "\n",
      "{'optimizer': 'sgd', 'nrCamadas': 8, 'epochs': 8, 'batch_size': 128, 'ativacao': 'exponential', 'topologia': [32, 10, 5, 4, 16, 8, 16, 10]}\n",
      "\n",
      "{'optimizer': 'rmsprop', 'nrCamadas': 1, 'epochs': 4, 'batch_size': 256, 'ativacao': 'sigmoid', 'topologia': [3]}\n"
     ]
    }
   ],
   "source": [
    "parametros = selecaoHyperParametros(dicionario,neuronios)\n",
    "for var in parametros:\n",
    "    print()\n",
    "    print(var)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
